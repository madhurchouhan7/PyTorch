{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f940474",
   "metadata": {},
   "source": [
    "# **üìã Pneumonia Detection with ResNet & PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e2825",
   "metadata": {},
   "source": [
    "### **Project Goal**\n",
    "To build a Deep Learning model that looks at Chest X-Ray images and predicts if a patient has **Pneumonia** or is **Normal**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf33a25",
   "metadata": {},
   "source": [
    "### **1. Imports and Setup**\n",
    "*   **`torch` & `torchvision`**: The main PyTorch libraries for building AI and handling images.\n",
    "*   **`os`**: To navigate files on your computer.\n",
    "*   **`matplotlib` & `seaborn`**: For drawing graphs and showing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce5b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febec470",
   "metadata": {},
   "source": [
    "Makes the chart appear directly inside the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbc1b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fab075",
   "metadata": {},
   "source": [
    "### **2. Configuration (Constants)**\n",
    "*   **`IMAGE_SIZE = 150`**: Neural Networks need fixed inputs. We will squash all images (big or small) to 150x150 pixels.\n",
    "*   **`BATCH_SIZE = 32`**: The \"Mini-Batch\" size. The model will study 32 images at a time before updating its brain.\n",
    "*   **`DATA_DIR`**: The path where your folders (train/test/val) live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ddbee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2341320299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/chest_xray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 64  # ‚ö° Increased from 32 (2x faster!)\n",
    "DATA_DIR = '/content/drive/MyDrive/chest_xray'  # Update this path to where you uploaded the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47aa4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üñ•Ô∏è  Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"‚ö° CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"üìä GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Test actual speed\n",
    "import time\n",
    "x = torch.randn(1000, 1000).cuda()\n",
    "start = time.time()\n",
    "y = x @ x\n",
    "torch.cuda.synchronize()\n",
    "print(f\"‚è±Ô∏è  GPU Speed Test: {(time.time()-start)*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0876f1",
   "metadata": {},
   "source": [
    "### **3. Data Transforms (The Preprocessing Pipeline)**\n",
    "Before an image enters the model, it must be \"cleaned\" and prepared. \n",
    "\n",
    "*   **`Grayscale(3)`**: \n",
    "     *   *Concept:* X-rays are Black & White (1 channel), but ResNet expects Color (3 channels).\n",
    "     *   *Trick:* We duplicate the B&W layer 3 times to \"fake\" a color image so ResNet accepts it.\n",
    "\n",
    "*   **`Resize`**: Ensures every image is exactly 150x150.\n",
    "\n",
    "*   **`ToTensor`**: Converts the image from **Pixels (0-255)** to **Math Numbers (0.0-1.0)**.\n",
    "\n",
    "*   **`Normalize`**: Shifts the math numbers to be between **-1 and 1**. This helps the model learn faster (stable gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1db813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMERS (grayscale, resize, to tensor, normalize)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528555e",
   "metadata": {},
   "source": [
    "### **4. Loading Data (The \"Bridge\")**\n",
    "*   **`ImageFolder`**: PyTorch's magic tool. It looks at folder names (\"Normal\", \"Pneumonia\") and automatically converts them into labels (0, 1).\n",
    "*   **`DataLoader`**: The \"Delivery Truck\". It gathers images from the hard drive, packages them into batches of 32, and delivers them to the GPU.\n",
    "    *   **`shuffle=True` (Train)**: Critical! We mix up the cards so the model doesn't memorize the order.     \n",
    "    *   **`shuffle=False` (Test)**: We don't need to shuffle when testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASETS\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'val'), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'test'), transform=transform)\n",
    "\n",
    "# ‚ö° Optimized DataLoaders for speed\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=2,           # Parallel loading\n",
    "    pin_memory=True,         # Faster GPU transfer\n",
    "    persistent_workers=True  # Keep workers alive\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=2, \n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=2, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Classes : \", train_dataset.classes)\n",
    "print(\"‚úÖ Dataset sizes : Train\", len(train_dataset))\n",
    "print(\"‚úÖ Dataset sizes : Validation\", len(val_dataset))\n",
    "print(\"‚úÖ Dataset sizes : Test\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e33c3b",
   "metadata": {},
   "source": [
    "### **5. Data Visualization (Checking for Imbalance)**\n",
    "*   **The Problem:** In medical data, \"Disease\" cases are often rare. If we have 1000 Normal and only 50 Pneumonia, the model might just guess \"Normal\" every time.\n",
    "*   **The Fix:** We plot a bar chart to see if we need to fix this (e.g., using Weighted Loss later).\n",
    " \n",
    "**üöÄ PERFORMANCE TIP:** \n",
    "*   I replaced your old code `[label for...]` which loaded *every image pixel* (taking minutes).\n",
    "*   I used `train_dataset.targets` which reads *only the labels* (taking milliseconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FAST WAY: Access the labels directly from the list stored in memory\n",
    "# This takes 0.01 seconds instead of 10 minutes\n",
    "labels = train_dataset.targets \n",
    "label_counts = Counter(labels)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "class_labels = [class_names[i] for i in label_counts.keys()]\n",
    "counts = list(label_counts.values())\n",
    "\n",
    "# PLOTTING\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(class_labels, counts, color=['green', 'red'])\n",
    "plt.title(\"Class Distribution in Training Set\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f10094",
   "metadata": {},
   "source": [
    "### **6. Sanity Check (View the Images)**\n",
    "*   **Concept:** Always look at your data! Did the resize work? Is \"Pneumonia\" actually labeled correctly?\n",
    "*   **`unnormalize`**: The images are currently number ranges [-1, 1] (weird colors). We calculate `img * 0.5 + 0.5` to bring them back to  so our eyes can see them normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc962307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl, class_names):\n",
    "    \n",
    "    # Fetch one batch from the dataloader\n",
    "    images, labels = next(iter(dl))\n",
    "    fig, axes = plt.subplots(3, 8, figsize=(15, 6))\n",
    "\n",
    "    # Show images up to batch size\n",
    "    num_images = len(images)\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < num_images:\n",
    "            img = images[i].numpy().transpose((1, 2, 0))\n",
    "            \n",
    "            img = (img * 0.5) + 0.5  # unnormalize \n",
    "            ax.imshow(img)\n",
    "            ax.set_title(class_names[labels[i]])\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    plt.suptitle(\"Sample Images from Training Set\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_batch(train_loader, train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2cdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaCNN(nn.Module):\n",
    "    def __init__(self, input_size=150):\n",
    "        super(PneumoniaCNN, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # Calculate flattened size dynamically\n",
    "        # After 3 pooling layers: input_size // 2 // 2 // 2\n",
    "        final_size = input_size // 8\n",
    "        flattened_size = 128 * final_size * final_size\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(flattened_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f678b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# initialize model with correct input size\n",
    "model = PneumoniaCNN(input_size=IMAGE_SIZE).to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "# handle class imbalance : calculate weights\n",
    "labels = [label for _, label in train_dataset.imgs]\n",
    "class_counts = Counter(labels)\n",
    "total = sum(class_counts.values())\n",
    "weights = [total / class_counts[i] for i in range(len(class_counts))]\n",
    "\n",
    "# Define loss function with weights\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler\n",
    "from torch import amp\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train_model(model, loader):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    pbar = tqdm(loader, desc='Training', unit='batch')\n",
    "\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # ‚ö° MIXED PRECISION: 2-3x faster!\n",
    "        with amp.autocast(device_type='cuda'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Use scaler instead of regular backward\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "        pbar.set_postfix({'loss': total_loss / len(loader), 'accuracy': correct / len(loader.dataset)})\n",
    "\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Validating\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # ‚ö° Use mixed precision for validation too\n",
    "        with amp.autocast(device_type='cuda'):\n",
    "            for images, labels in pbar:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_loss += loss.item() \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "                pbar.set_postfix({'loss': total_loss / len(loader), 'accuracy': correct / len(loader.dataset)})\n",
    "\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43156188",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5  ## change to 25 for better results\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS + 1):\n",
    "    train_loss, train_accuracy = train_model(model, train_loader)\n",
    "    \n",
    "    # ‚ö° Validate every 2 epochs (except first and last)\n",
    "    if epoch % 2 == 0 or epoch == NUM_EPOCHS:\n",
    "        val_loss, val_accuracy = validate_model(model, val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        scheduler.step(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{NUM_EPOCHS}  \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Acc: {train_accuracy:.4f}  \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Acc: {val_accuracy:.4f}\", flush=True)\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_pneumonia_cnn.pth')\n",
    "            print(\"=> Saved Best Model\", flush=True)\n",
    "    else:\n",
    "        print(f\"Epoch {epoch}/{NUM_EPOCHS}  \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Acc: {train_accuracy:.4f}\", flush=True)\n",
    "\n",
    "print(f\"üéØ Best validation Accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epoch indices that match validation points\n",
    "validation_epochs = [i for i in range(NUM_EPOCHS + 1) if i % 2 == 0 or i == NUM_EPOCHS]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(validation_epochs, train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(validation_epochs, val_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(validation_epochs, train_accuracies, label='Train Accuracy', marker='o')\n",
    "plt.plot(validation_epochs, val_accuracies, label='Validation Accuracy', marker='o')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05830ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128\n",
    "\n",
    "# safer medical augmentation for training\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "    transforms.RandomRotation(degrees=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "data_dir = 'data/chest_xray'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=test_val_transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_val_transform)\n",
    "\n",
    "BATCH_SIZE = 16 # can increase to 32 later\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(\"‚úÖ Classes : \", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ba331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch of training data\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# denormalize images for visualization\n",
    "def denormalize(img):\n",
    "    img = img * 0.5 + 0.5  # unnormalize\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    return img\n",
    "\n",
    "\n",
    "# plot a grid of images\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(min(BATCH_SIZE, 16)):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(denormalize(images[i]))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96b30d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 121MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.conv_block1 = nn.Conv2d(1, 64, kernel_size = 7, stride=2, padding=3, bias=False)\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with early stopping and checkpointing\n",
    "\n",
    "import copy\n",
    "\n",
    "# CONFIGURATIONS\n",
    "NUM_EPOCHS = 25\n",
    "PATIENCE = 5  # for early stopping\n",
    "BEST_MODEL_PATH = 'best_resnet18_pneumonia.pth'\n",
    "\n",
    "# Loss, Optimizer, Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# logging\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# early stopping \n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct , total= 0, 0, 0\n",
    "\n",
    "    for images, lable in train_loader:\n",
    "        images = images.to(device)\n",
    "        lable = lable.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, lable)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.max(1)[1]\n",
    "        correct += preds.eq(lable).sum().item()\n",
    "        total += lable.size(0)\n",
    "\n",
    "\n",
    "    train_loss /= total\n",
    "    train_accuracy = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # validation phase\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, lable in val_loader:\n",
    "            images = images.to(device)\n",
    "            lable = lable.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, lable)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = outputs.max(1)[1]\n",
    "            correct += preds.eq(lable).sum().item()\n",
    "            total += lable.size(0)\n",
    "\n",
    "    val_loss /= total\n",
    "    val_accuracy = correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    scheduler.step(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}  Train Loss: {train_loss:.4f}, Acc: {train_accuracy:.4f}  Val Loss: {val_loss:.4f}, Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    # check for improvement\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        epochs_no_improve = 0\n",
    "        print(\"üìå Best model saved.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "        # early stopping\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(f\"‚úÖ Training completed. Best Validation Accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786570b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_range, train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(epoch_range, val_losses, label='Validation Loss', color='orange')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_range, train_accuracies, label='Train Accuracy', color='blue')\n",
    "plt.plot(epoch_range, val_accuracies, label='Validation Accuracy', color='orange')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# collect all predictions and true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = outputs.max(1)[1]\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# generate classification report\n",
    "class_names = ['Normal', 'Pneumonia']\n",
    "print(\"üìä Classification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "\n",
    "# plot confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ad03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. generate predictions on True labels\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = outputs.max(1)[1]\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "# step 2. Find correct and incorrect predictions\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "correct_indices = np.where(all_preds == all_labels)[0]\n",
    "incorrect_indices = np.where(all_preds != all_labels)[0]\n",
    "\n",
    "\n",
    "# step 3. Visualize some correct predictions\n",
    "def show_images(indices, title, n=16):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, idx in enumerate(indices[:n]):\n",
    "        image, label = test_dataset[idx]\n",
    "        image = denormalize(image)\n",
    "\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Pred: {class_names[all_preds[idx]]}\\nTrue: {class_names[label]}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# step 4. Show correct predictions\n",
    "show_images(correct_indices, \"‚úÖ Correct Predictions\")\n",
    "show_images(incorrect_indices, \"‚ùå Incorrect Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80644934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Labels for entire training dataset (flattened)\n",
    "all_labels = [label for _, label in train_dataset]  # or your raw labels array\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(all_labels), y=all_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.3, patience=2, verbose=True, min_lr=1e-6)\n",
    "\n",
    "# Early stopping setup\n",
    "best_val_acc = 0\n",
    "early_stop_counter = 0\n",
    "PATIENCE = 5\n",
    "EPOCHS = 20\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "\n",
    "    val_loss /= total\n",
    "    val_acc = correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}  Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}  Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Learning rate update\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    # Checkpoint and early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"resnet18_pneumonia_best.pth\")\n",
    "        print(\"üìå Best model saved.\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= PATIENCE:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"‚úÖ Training complete.\")\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"resnet18_pneumonia_best.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# üìâ Loss Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(epochs_range, val_losses, label='Val Loss', color='orange')\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# üìà Accuracy Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_accuracies, label='Train Accuracy', color='blue')\n",
    "plt.plot(epochs_range, val_accuracies, label='Val Accuracy', color='orange')\n",
    "plt.title(\"Accuracy Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix on Test Set\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
