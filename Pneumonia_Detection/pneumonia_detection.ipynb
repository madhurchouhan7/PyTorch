{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f940474",
   "metadata": {},
   "source": [
    "# **ðŸ“‹ Pneumonia Detection with ResNet & PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e2825",
   "metadata": {},
   "source": [
    "### **Project Goal**\n",
    "To build a Deep Learning model that looks at Chest X-Ray images and predicts if a patient has **Pneumonia** or is **Normal**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf33a25",
   "metadata": {},
   "source": [
    "### **1. Imports and Setup**\n",
    "*   **`torch` & `torchvision`**: The main PyTorch libraries for building AI and handling images.\n",
    "*   **`os`**: To navigate files on your computer.\n",
    "*   **`matplotlib` & `seaborn`**: For drawing graphs and showing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce5b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febec470",
   "metadata": {},
   "source": [
    "Makes the chart appear directly inside the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbc1b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fab075",
   "metadata": {},
   "source": [
    "### **2. Configuration (Constants)**\n",
    "*   **`IMAGE_SIZE = 150`**: Neural Networks need fixed inputs. We will squash all images (big or small) to 150x150 pixels.\n",
    "*   **`BATCH_SIZE = 32`**: The \"Mini-Batch\" size. The model will study 32 images at a time before updating its brain.\n",
    "*   **`DATA_DIR`**: The path where your folders (train/test/val) live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "603ddbee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2341320299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/chest_xray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/MyDrive/chest_xray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "IMAGE_SIZE = 150\n",
    "BATCH_SIZE = 16 # 32 for later\n",
    "DATA_DIR = '/content/drive/MyDrive/chest_xray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47aa4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0876f1",
   "metadata": {},
   "source": [
    "### **3. Data Transforms (The Preprocessing Pipeline)**\n",
    "Before an image enters the model, it must be \"cleaned\" and prepared. \n",
    "\n",
    "*   **`Grayscale(3)`**: \n",
    "     *   *Concept:* X-rays are Black & White (1 channel), but ResNet expects Color (3 channels).\n",
    "     *   *Trick:* We duplicate the B&W layer 3 times to \"fake\" a color image so ResNet accepts it.\n",
    "\n",
    "*   **`Resize`**: Ensures every image is exactly 150x150.\n",
    "\n",
    "*   **`ToTensor`**: Converts the image from **Pixels (0-255)** to **Math Numbers (0.0-1.0)**.\n",
    "\n",
    "*   **`Normalize`**: Shifts the math numbers to be between **-1 and 1**. This helps the model learn faster (stable gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1db813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMERS (grayscale, resize, to tensor, normalize)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528555e",
   "metadata": {},
   "source": [
    "### **4. Loading Data (The \"Bridge\")**\n",
    "*   **`ImageFolder`**: PyTorch's magic tool. It looks at folder names (\"Normal\", \"Pneumonia\") and automatically converts them into labels (0, 1).\n",
    "*   **`DataLoader`**: The \"Delivery Truck\". It gathers images from the hard drive, packages them into batches of 32, and delivers them to the GPU.\n",
    "    *   **`shuffle=True` (Train)**: Critical! We mix up the cards so the model doesn't memorize the order.     \n",
    "    *   **`shuffle=False` (Test)**: We don't need to shuffle when testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASETS\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'val'), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'test'), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"âœ… Classes : \", train_dataset.classes)\n",
    "print(\"âœ… Dataset sizes : Train\", len(train_dataset))\n",
    "print(\"âœ… Dataset sizes : Validation\", len(val_dataset))\n",
    "print(\"âœ… Dataset sizes : Test\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e33c3b",
   "metadata": {},
   "source": [
    "### **5. Data Visualization (Checking for Imbalance)**\n",
    "*   **The Problem:** In medical data, \"Disease\" cases are often rare. If we have 1000 Normal and only 50 Pneumonia, the model might just guess \"Normal\" every time.\n",
    "*   **The Fix:** We plot a bar chart to see if we need to fix this (e.g., using Weighted Loss later).\n",
    " \n",
    "**ðŸš€ PERFORMANCE TIP:** \n",
    "*   I replaced your old code `[label for...]` which loaded *every image pixel* (taking minutes).\n",
    "*   I used `train_dataset.targets` which reads *only the labels* (taking milliseconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FAST WAY: Access the labels directly from the list stored in memory\n",
    "# This takes 0.01 seconds instead of 10 minutes\n",
    "labels = train_dataset.targets \n",
    "label_counts = Counter(labels)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "class_labels = [class_names[i] for i in label_counts.keys()]\n",
    "counts = list(label_counts.values())\n",
    "\n",
    "# PLOTTING\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(class_labels, counts, color=['green', 'red'])\n",
    "plt.title(\"Class Distribution in Training Set\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f10094",
   "metadata": {},
   "source": [
    "### **6. Sanity Check (View the Images)**\n",
    "*   **Concept:** Always look at your data! Did the resize work? Is \"Pneumonia\" actually labeled correctly?\n",
    "*   **`unnormalize`**: The images are currently number ranges [-1, 1] (weird colors). We calculate `img * 0.5 + 0.5` to bring them back to  so our eyes can see them normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc962307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl, class_names):\n",
    "    \n",
    "    # Fetch one batch from the dataloader\n",
    "    images, labels = next(iter(dl))\n",
    "    fig, axes = plt.subplots(3, 8, figsize=(15, 6))\n",
    "\n",
    "    # Show images up to batch size\n",
    "    num_images = len(images)\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < num_images:\n",
    "            img = images[i].numpy().transpose((1, 2, 0))\n",
    "            \n",
    "            img = (img * 0.5) + 0.5  # unnormalize \n",
    "            ax.imshow(img)\n",
    "            ax.set_title(class_names[labels[i]])\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    plt.suptitle(\"Sample Images from Training Set\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_batch(train_loader, train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.conv_block1 = nn.Conv2d(1, 64, kernel_size = 7, stride=2, padding=3, bias=False)\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2cdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PneumoniaCNN, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128 * 18 * 18, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f678b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# initialize model \n",
    "model = PneumoniaCNN().to(device)\n",
    "\n",
    "# handle class imbalance : calculate weights\n",
    "labels = [label for _, label in train_dataset.imgs]\n",
    "class_counts = Counter(labels)\n",
    "total = sum(class_counts.values())\n",
    "weights = [total / class_counts[i] for i in range(len(class_counts))]\n",
    "\n",
    "# Define loss function with weights\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, loader):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "\n",
    "    # add progress bar\n",
    "\n",
    "    pbar = tqdm(loader, desc='Training', unit='batch')\n",
    "\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "        # update progress bar with current loss and accuracy\n",
    "        pbar.set_postfix({'loss': total_loss / (len(loader)), 'accuracy': correct / ((len(loader.dataset)))})\n",
    "\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    # â† Add progress bar\n",
    "    pbar = tqdm(loader, desc=\"Validating\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            pbar.set_postfix({'loss': total_loss / (len(loader)), 'accuracy': correct / ((len(loader.dataset)))})\n",
    "\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43156188",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5 ## change to 25 for better results\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS + 1):\n",
    "    train_loss, train_accuracy = train_model(model, train_loader)\n",
    "    val_loss, val_accuracy = validate_model(model, val_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # adjust learning rate\n",
    "    scheduler.step(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS}  \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Acc: {train_accuracy:.4f}  \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Acc: {val_accuracy:.4f}\", flush=True)\n",
    "    \n",
    "    # save best model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), 'best_pneumonia_cnn.pth')\n",
    "        print(\"=> Saved Best Model\", flush=True)\n",
    "\n",
    "print(f\"ðŸŽ¯ Best validation Accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05830ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 150\n",
    "\n",
    "# safer medical augmentation for training\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "    transforms.RandomRotation(degrees=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "data_dir = 'data/chest_xray'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=test_val_transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_val_transform)\n",
    "\n",
    "BATCH_SIZE = 16 # can increase to 32 later\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(\"âœ… Classes : \", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ba331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch of training data\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# denormalize images for visualization\n",
    "def denormalize(img):\n",
    "    img = img * 0.5 + 0.5  # unnormalize\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    return img\n",
    "\n",
    "\n",
    "# plot a grid of images\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(min(BATCH_SIZE, 16)):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(denormalize(images[i]))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b30d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
