{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a8a565",
   "metadata": {},
   "source": [
    "# ðŸ« Lung Cancer Classification with Ensemble Learning\n",
    "\n",
    "## ðŸŽ¯ Project Goal: Achieve >98% Accuracy using Ensemble Methods\n",
    "\n",
    "This notebook implements **5 state-of-the-art models** and **multiple ensemble techniques** to achieve maximum accuracy in lung cancer detection from CT scan images.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“¦ What's Included:\n",
    "\n",
    "### ðŸ—ï¸ **Individual Models:**\n",
    "1. **CNN with Batch Normalization** (98.83% baseline from your original work)\n",
    "2. **ResNet18** (Transfer Learning)\n",
    "3. **ResNet50** (Transfer Learning)\n",
    "4. **VGG16** (Transfer Learning)\n",
    "5. **InceptionV3** (Transfer Learning)\n",
    "\n",
    "### ðŸŽ¯ **Ensemble Methods:**\n",
    "1. **Voting Ensemble**\n",
    "   - Hard Voting (Majority vote)\n",
    "   - Soft Voting (Average probabilities)\n",
    "   \n",
    "2. **Weighted Ensemble**\n",
    "   - Performance-based weights\n",
    "   - Optimized for validation accuracy\n",
    "   \n",
    "3. **Stacking Ensemble**\n",
    "   - Level 0: All base models\n",
    "   - Level 1: Random Forest or Logistic Regression meta-classifier\n",
    "   \n",
    "4. **Bagging-style** (Multiple model diversity)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ–ï¸ Expected Performance:\n",
    "\n",
    "| Method | Expected Accuracy |\n",
    "|--------|------------------|\n",
    "| CNN Baseline | 98.83% |\n",
    "| ResNet18/50 | 96-98% |\n",
    "| VGG16 | 96-97% |\n",
    "| InceptionV3 | 96-98% |\n",
    "| **Soft Voting Ensemble** | **>98%** âœ… |\n",
    "| **Weighted Ensemble** | **>98%** âœ… |\n",
    "| **Stacking Ensemble** | **>99%** ðŸŽ¯ |\n",
    "\n",
    "---\n",
    "\n",
    "## â±ï¸ Training Time Estimate:\n",
    "- **Total:** ~2-3 hours (on Google Colab T4 GPU)\n",
    "- **CNN:** 15-20 min\n",
    "- **ResNet18:** 20-25 min\n",
    "- **ResNet50:** 30-40 min\n",
    "- **VGG16:** 35-45 min\n",
    "- **InceptionV3:** 30-40 min\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Quick Start:\n",
    "1. Run all data loading cells\n",
    "2. Run model definition cells\n",
    "3. Execute training cell (takes 2-3 hours)\n",
    "4. Evaluate ensemble methods\n",
    "5. View results and visualizations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb58075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c02b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/content/drive/MyDrive/Final_Split_Data\"\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa3b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¥ï¸  Device: CPU\n",
      "âš¡ CUDA Available: False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ–¥ï¸  Device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš¡ CUDA Available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“Š GPU Memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtotal_memory\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1e9\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Test actual speed\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Madhur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:614\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_properties\u001b[39m(device: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    603\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \n\u001b[0;32m    605\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 614\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    615\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32mc:\\Users\\Madhur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m     )\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "print(f\"ðŸ–¥ï¸  Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"âš¡ CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"ðŸ“Š GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Test actual speed\n",
    "import time\n",
    "x = torch.randn(1000, 1000).cuda()\n",
    "start = time.time()\n",
    "y = x @ x\n",
    "torch.cuda.synchronize()\n",
    "print(f\"â±ï¸  GPU Speed Test: {(time.time()-start)*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ffc9e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyCLAHE:\n",
    "    def __init__(self, clip_limit=1, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "\n",
    "        # convert PIL image to numpy array\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # apply CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "\n",
    "        # if gray scale\n",
    "        if len(img_np.shape) == 2:\n",
    "            img_clahe = clahe.apply(img_np)\n",
    "\n",
    "        # if RGB, apply to each channel\n",
    "        else:\n",
    "            img_clahe = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "            img_clahe[:, :, 0] = clahe.apply(img_clahe[:, :, 0])\n",
    "            img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "        return Image.fromarray(img_clahe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a75735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    ApplyCLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMAGE_SIZE + 10, IMAGE_SIZE + 10)),\n",
    "    transforms.RandomCrop((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe1b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val/Test transforms (deterministic)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    ApplyCLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Direct resize, no crop\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce77edaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/Final_Split_Data\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# laod dataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m), transform\u001b[38;5;241m=\u001b[39mval_test_transforms)\n\u001b[0;32m      5\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m), transform\u001b[38;5;241m=\u001b[39mval_test_transforms)\n",
      "File \u001b[1;32mc:\\Users\\Madhur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m ):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\Madhur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[0;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\Madhur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Madhur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_classes\u001b[39m(directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/Final_Split_Data\\\\train'"
     ]
    }
   ],
   "source": [
    "# laod dataset\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"test\"), transform=val_test_transforms)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"), transform=val_test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55d7973",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain_dataset\u001b[49m,\n\u001b[0;32m      3\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m      4\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      6\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m     persistent_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     11\u001b[0m     test_dataset,\n\u001b[0;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     persistent_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     20\u001b[0m     val_dataset,\n\u001b[0;32m     21\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     persistent_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     26\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=3,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=3,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=3,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… Data loaded successfully!\")\n",
    "print(\"âœ… Classes : \", train_dataset.classes)\n",
    "print(\"âœ… Dataset sizes : Train\", len(train_dataset))\n",
    "print(\"âœ… Dataset sizes : Validation\", len(val_dataset))\n",
    "print(\"âœ… Dataset sizes : Test\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc309e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afcd6979",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mtargets\n\u001b[0;32m      5\u001b[0m label_counts \u001b[38;5;241m=\u001b[39m Counter(labels)\n\u001b[0;32m      7\u001b[0m class_names \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mclasses\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = train_dataset.targets\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "class_labels = [class_names[i] for i in label_counts.keys()]\n",
    "counts = list(label_counts.values())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(class_labels, counts, color=['red', 'green'])\n",
    "plt.title(\"Class Distribution in Training Set\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "309ef554",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Call with dataset instead of dataloader\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m show_batch(\u001b[43mtrain_dataset\u001b[49m, train_dataset\u001b[38;5;241m.\u001b[39mclasses)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def show_batch(dataset, class_names, num_images=24):\n",
    "\n",
    "    # Get images directly from dataset (much faster)\n",
    "    indices = np.random.choice(len(dataset), min(num_images, len(dataset)), replace=False)\n",
    "\n",
    "    rows = 3\n",
    "    cols = 5\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 6))\n",
    "\n",
    "    # Unnormalize parameters\n",
    "    mean = torch.tensor([0.485, 0.485, 0.485]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.229, 0.229]).view(3, 1, 1)\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(indices):\n",
    "            img, label = dataset[indices[i]]\n",
    "\n",
    "            # Unnormalize\n",
    "            img = img * std + mean\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "\n",
    "            # Convert to numpy\n",
    "            img = img.numpy().transpose((1, 2, 0))\n",
    "\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title(class_names[label], fontsize=10)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.suptitle(\"Sample Images from Training Set\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call with dataset instead of dataloader\n",
    "show_batch(train_dataset, train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313697c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0362f539",
   "metadata": {},
   "source": [
    "# ðŸ§  Model Architectures\n",
    "\n",
    "## 1ï¸âƒ£ CNN with Batch Normalization (98.83% accuracy baseline)\n",
    "## 2ï¸âƒ£ ResNet18 & ResNet50 (Transfer Learning)\n",
    "## 3ï¸âƒ£ VGG16 & InceptionV3 (Additional models)\n",
    "## 4ï¸âƒ£ Ensemble Methods (Voting, Stacking, Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6635709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ–¥ï¸  Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ðŸ“Š GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸  Running on CPU (training will be slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596794c0",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Model 1: CNN with Batch Normalization (98.83% Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungCancerCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN with Batch Normalization - 98.83% Test Accuracy\n",
    "    \n",
    "    Architecture:\n",
    "    - Block 1: Conv(32) â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ Dropout(0.25)\n",
    "    - Block 2: Conv(64) â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ Dropout(0.25)\n",
    "    - Block 3: Conv(128) â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ Dropout(0.3)\n",
    "    - FC: 512 â†’ Dropout(0.5) â†’ 2 classes\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(LungCancerCNN, self).__init__()\n",
    "\n",
    "        # Block 1: Conv(32) â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ Dropout(0.25)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "\n",
    "        # Block 2: Conv(64) â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ Dropout(0.25)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "\n",
    "        # Block 3: Conv(128) â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ Dropout(0.3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout3 = nn.Dropout2d(0.3)\n",
    "\n",
    "        # Calculate flattened size: 224 / 2 / 2 / 2 = 28\n",
    "        self.flatten_size = 28 * 28 * 128\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 512)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # Block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # Block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "print(\"âœ… LungCancerCNN defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb74509",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Model 2 & 3: ResNet18 & ResNet50 (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungCancerResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-based Lung Cancer Classifier (Transfer Learning)\n",
    "    \n",
    "    Supports: ResNet18, ResNet50\n",
    "    Pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2, model_type='resnet18', pretrained=True):\n",
    "        super(LungCancerResNet, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet\n",
    "        if model_type == 'resnet18':\n",
    "            self.resnet = models.resnet18(pretrained=pretrained)\n",
    "            print(f\"âœ… Loaded ResNet18 (pretrained={pretrained})\")\n",
    "        elif model_type == 'resnet50':\n",
    "            self.resnet = models.resnet50(pretrained=pretrained)\n",
    "            print(f\"âœ… Loaded ResNet50 (pretrained={pretrained})\")\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'resnet18' or 'resnet50'\")\n",
    "        \n",
    "        # Get number of features from last layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        \n",
    "        # Replace final layer with custom classifier\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "print(\"âœ… LungCancerResNet defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f9c8de",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Model 4 & 5: VGG16 & InceptionV3 (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34159e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungCancerVGG16(nn.Module):\n",
    "    \"\"\"VGG16-based Lung Cancer Classifier\"\"\"\n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(LungCancerVGG16, self).__init__()\n",
    "        \n",
    "        # Load pretrained VGG16\n",
    "        self.vgg = models.vgg16(pretrained=pretrained)\n",
    "        print(f\"âœ… Loaded VGG16 (pretrained={pretrained})\")\n",
    "        \n",
    "        # Get number of features from last layer\n",
    "        num_features = self.vgg.classifier[6].in_features\n",
    "        \n",
    "        # Replace final layer\n",
    "        self.vgg.classifier[6] = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.vgg(x)\n",
    "\n",
    "\n",
    "class LungCancerInceptionV3(nn.Module):\n",
    "    \"\"\"InceptionV3-based Lung Cancer Classifier\"\"\"\n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(LungCancerInceptionV3, self).__init__()\n",
    "        \n",
    "        # Load pretrained InceptionV3\n",
    "        self.inception = models.inception_v3(pretrained=pretrained, aux_logits=True)\n",
    "        print(f\"âœ… Loaded InceptionV3 (pretrained={pretrained})\")\n",
    "        \n",
    "        # Get number of features from last layer\n",
    "        num_features = self.inception.fc.in_features\n",
    "        \n",
    "        # Replace final layer\n",
    "        self.inception.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Also modify auxiliary classifier\n",
    "        if self.inception.aux_logits:\n",
    "            num_aux_features = self.inception.AuxLogits.fc.in_features\n",
    "            self.inception.AuxLogits.fc = nn.Linear(num_aux_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            outputs, aux_outputs = self.inception(x)\n",
    "            return outputs\n",
    "        else:\n",
    "            return self.inception(x)\n",
    "\n",
    "print(\"âœ… VGG16 and InceptionV3 defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0954d86",
   "metadata": {},
   "source": [
    "# ðŸ‹ï¸ Training & Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100 * correct / total:.2f}%'\n",
    "        })\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"Validation\", leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100 * correct / total:.2f}%'\n",
    "            })\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def get_predictions(model, dataloader, device):\n",
    "    \"\"\"Get predictions and true labels for a dataset\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Getting predictions\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "print(\"âœ… Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618b5c1",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Ensemble Methods\n",
    "\n",
    "## 1ï¸âƒ£ Voting Ensemble (Hard & Soft)\n",
    "## 2ï¸âƒ£ Stacking Ensemble (Meta-learner)\n",
    "## 3ï¸âƒ£ Bagging Ensemble (Multiple instances)\n",
    "## 4ï¸âƒ£ Weighted Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingEnsemble:\n",
    "    \"\"\"\n",
    "    Voting Ensemble: Combines predictions from multiple models\n",
    "    \n",
    "    - Hard Voting: Majority vote\n",
    "    - Soft Voting: Average probabilities\n",
    "    \"\"\"\n",
    "    def __init__(self, models, device, voting='soft'):\n",
    "        self.models = models\n",
    "        self.device = device\n",
    "        self.voting = voting  # 'hard' or 'soft'\n",
    "    \n",
    "    def predict(self, dataloader):\n",
    "        \"\"\"Get ensemble predictions\"\"\"\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        for model in self.models:\n",
    "            preds, labels, probs = get_predictions(model, dataloader, self.device)\n",
    "            all_preds.append(preds)\n",
    "            all_probs.append(probs)\n",
    "            if len(all_labels) == 0:\n",
    "                all_labels = labels\n",
    "        \n",
    "        all_preds = np.array(all_preds)  # Shape: (num_models, num_samples)\n",
    "        all_probs = np.array(all_probs)  # Shape: (num_models, num_samples, num_classes)\n",
    "        \n",
    "        if self.voting == 'hard':\n",
    "            # Majority vote\n",
    "            final_preds = []\n",
    "            for i in range(all_preds.shape[1]):\n",
    "                votes = all_preds[:, i]\n",
    "                final_preds.append(np.bincount(votes).argmax())\n",
    "            final_preds = np.array(final_preds)\n",
    "        else:\n",
    "            # Soft voting (average probabilities)\n",
    "            avg_probs = np.mean(all_probs, axis=0)  # Average across models\n",
    "            final_preds = np.argmax(avg_probs, axis=1)\n",
    "        \n",
    "        accuracy = 100 * np.mean(final_preds == all_labels)\n",
    "        return final_preds, all_labels, accuracy\n",
    "\n",
    "\n",
    "class StackingEnsemble:\n",
    "    \"\"\"\n",
    "    Stacking Ensemble: Uses a meta-classifier\n",
    "    \n",
    "    Level 0: Base models (CNN, ResNet, VGG, etc.)\n",
    "    Level 1: Meta-classifier (Random Forest or Logistic Regression)\n",
    "    \"\"\"\n",
    "    def __init__(self, base_models, meta_classifier, device):\n",
    "        self.base_models = base_models\n",
    "        self.meta_classifier = meta_classifier\n",
    "        self.device = device\n",
    "    \n",
    "    def fit(self, train_loader, val_loader):\n",
    "        \"\"\"Train meta-classifier on base model predictions\"\"\"\n",
    "        print(\"ðŸ”¨ Training stacking ensemble...\")\n",
    "        \n",
    "        # Get base model predictions on training set\n",
    "        train_probs_list = []\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            print(f\"   Getting predictions from model {i+1}/{len(self.base_models)}\")\n",
    "            _, _, probs = get_predictions(model, train_loader, self.device)\n",
    "            train_probs_list.append(probs)\n",
    "        \n",
    "        # Concatenate all probabilities as features\n",
    "        X_train = np.concatenate(train_probs_list, axis=1)\n",
    "        _, y_train, _ = get_predictions(self.base_models[0], train_loader, self.device)\n",
    "        \n",
    "        # Train meta-classifier\n",
    "        print(\"   Training meta-classifier...\")\n",
    "        self.meta_classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Validate\n",
    "        val_preds, val_labels, val_acc = self.predict(val_loader)\n",
    "        print(f\"âœ… Stacking ensemble validation accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "        return val_acc\n",
    "    \n",
    "    def predict(self, dataloader):\n",
    "        \"\"\"Get stacking ensemble predictions\"\"\"\n",
    "        # Get base model predictions\n",
    "        probs_list = []\n",
    "        for model in self.base_models:\n",
    "            _, labels, probs = get_predictions(model, dataloader, self.device)\n",
    "            probs_list.append(probs)\n",
    "        \n",
    "        # Concatenate as features\n",
    "        X = np.concatenate(probs_list, axis=1)\n",
    "        \n",
    "        # Meta-classifier prediction\n",
    "        final_preds = self.meta_classifier.predict(X)\n",
    "        accuracy = 100 * np.mean(final_preds == labels)\n",
    "        \n",
    "        return final_preds, labels, accuracy\n",
    "\n",
    "\n",
    "class WeightedEnsemble:\n",
    "    \"\"\"\n",
    "    Weighted Ensemble: Assigns weights to each model\n",
    "    \n",
    "    Weights can be:\n",
    "    - Equal: 1/n for each model\n",
    "    - Performance-based: Based on validation accuracy\n",
    "    - Optimized: Using optimization algorithms\n",
    "    \"\"\"\n",
    "    def __init__(self, models, weights, device):\n",
    "        self.models = models\n",
    "        self.weights = np.array(weights)\n",
    "        self.weights = self.weights / self.weights.sum()  # Normalize\n",
    "        self.device = device\n",
    "    \n",
    "    def predict(self, dataloader):\n",
    "        \"\"\"Get weighted ensemble predictions\"\"\"\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        for model in self.models:\n",
    "            _, labels, probs = get_predictions(model, dataloader, self.device)\n",
    "            all_probs.append(probs)\n",
    "            if len(all_labels) == 0:\n",
    "                all_labels = labels\n",
    "        \n",
    "        all_probs = np.array(all_probs)  # Shape: (num_models, num_samples, num_classes)\n",
    "        \n",
    "        # Weighted average\n",
    "        weighted_probs = np.zeros_like(all_probs[0])\n",
    "        for i, weight in enumerate(self.weights):\n",
    "            weighted_probs += weight * all_probs[i]\n",
    "        \n",
    "        final_preds = np.argmax(weighted_probs, axis=1)\n",
    "        accuracy = 100 * np.mean(final_preds == all_labels)\n",
    "        \n",
    "        return final_preds, all_labels, accuracy\n",
    "\n",
    "print(\"âœ… Ensemble classes defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a875bf",
   "metadata": {},
   "source": [
    "# ðŸš€ Training Individual Models\n",
    "\n",
    "**Note:** This will take some time! Each model trains separately.\n",
    "\n",
    "**Models to train:**\n",
    "1. CNN with BatchNorm (baseline: 98.83%)\n",
    "2. ResNet18 (transfer learning)\n",
    "3. ResNet50 (transfer learning)\n",
    "4. VGG16 (transfer learning)\n",
    "5. InceptionV3 (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8969379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name, train_loader, val_loader, num_epochs=20, \n",
    "                lr=0.001, patience=7, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train a single model with early stopping\n",
    "    \n",
    "    Returns: trained model, best validation accuracy, history\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸš€ Training {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-7\n",
    "    )\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nðŸ“… Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nðŸ“Š Results:\")\n",
    "        print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f\"   âœ… New best model! (Val Acc: {best_val_acc:.2f}%)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"   â³ No improvement ({patience_counter}/{patience})\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nâ¹ï¸  Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    print(f\"\\nâœ… {model_name} training complete!\")\n",
    "    print(f\"ðŸ“Š Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return model, best_val_acc, history\n",
    "\n",
    "print(\"âœ… Training function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c2f64f",
   "metadata": {},
   "source": [
    "## Train All Models (Run this cell to train everything)\n",
    "\n",
    "**Time estimate:** \n",
    "- CNN: ~15-20 min\n",
    "- ResNet18: ~20-25 min\n",
    "- ResNet50: ~30-40 min\n",
    "- VGG16: ~35-45 min\n",
    "- InceptionV3: ~30-40 min\n",
    "\n",
    "**Total: ~2-3 hours** (on Google Colab T4 GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all models\n",
    "models_dict = {}\n",
    "val_accuracies = {}\n",
    "\n",
    "# 1. CNN with BatchNorm\n",
    "print(\"ðŸ”¨ Creating CNN with BatchNorm...\")\n",
    "cnn_model = LungCancerCNN(num_classes=2).to(device)\n",
    "models_dict['CNN'] = cnn_model\n",
    "\n",
    "# 2. ResNet18\n",
    "print(\"ðŸ”¨ Creating ResNet18...\")\n",
    "resnet18_model = LungCancerResNet(num_classes=2, model_type='resnet18', pretrained=True).to(device)\n",
    "models_dict['ResNet18'] = resnet18_model\n",
    "\n",
    "# 3. ResNet50\n",
    "print(\"ðŸ”¨ Creating ResNet50...\")\n",
    "resnet50_model = LungCancerResNet(num_classes=2, model_type='resnet50', pretrained=True).to(device)\n",
    "models_dict['ResNet50'] = resnet50_model\n",
    "\n",
    "# 4. VGG16\n",
    "print(\"ðŸ”¨ Creating VGG16...\")\n",
    "vgg16_model = LungCancerVGG16(num_classes=2, pretrained=True).to(device)\n",
    "models_dict['VGG16'] = vgg16_model\n",
    "\n",
    "# 5. InceptionV3\n",
    "print(\"ðŸ”¨ Creating InceptionV3...\")\n",
    "inception_model = LungCancerInceptionV3(num_classes=2, pretrained=True).to(device)\n",
    "models_dict['InceptionV3'] = inception_model\n",
    "\n",
    "print(f\"\\nâœ… All {len(models_dict)} models created!\")\n",
    "print(\"\\nðŸ“Š Model Parameter Counts:\")\n",
    "for name, model in models_dict.items():\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"   {name}: {params:,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "trained_models = {}\n",
    "histories = {}\n",
    "\n",
    "# Training configuration\n",
    "training_config = {\n",
    "    'CNN': {'lr': 0.001, 'epochs': 30},\n",
    "    'ResNet18': {'lr': 0.0001, 'epochs': 25},\n",
    "    'ResNet50': {'lr': 0.0001, 'epochs': 25},\n",
    "    'VGG16': {'lr': 0.0001, 'epochs': 20},\n",
    "    'InceptionV3': {'lr': 0.0001, 'epochs': 20}\n",
    "}\n",
    "\n",
    "print(\"ðŸš€ Starting training for all models...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for model_name, model in models_dict.items():\n",
    "    config = training_config[model_name]\n",
    "    \n",
    "    # Train the model\n",
    "    trained_model, val_acc, history = train_model(\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=config['epochs'],\n",
    "        lr=config['lr'],\n",
    "        patience=7,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    trained_models[model_name] = trained_model\n",
    "    val_accuracies[model_name] = val_acc\n",
    "    histories[model_name] = history\n",
    "    \n",
    "    # Save model checkpoint\n",
    "    torch.save({\n",
    "        'model_state_dict': trained_model.state_dict(),\n",
    "        'val_accuracy': val_acc,\n",
    "        'history': history\n",
    "    }, f'{model_name}_checkpoint.pth')\n",
    "    \n",
    "    print(f\"ðŸ’¾ Saved {model_name} checkpoint\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… ALL MODELS TRAINED!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nðŸ“Š Validation Accuracies:\")\n",
    "for name, acc in sorted(val_accuracies.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {name}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e188eb0b",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Ensemble Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc982bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top models for ensemble (e.g., top 3-5)\n",
    "model_list = [trained_models[name] for name in trained_models.keys()]\n",
    "\n",
    "print(\"ðŸŽ¯ Evaluating Ensemble Methods on Test Set\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "ensemble_results = {}\n",
    "\n",
    "# 1. Hard Voting Ensemble\n",
    "print(\"\\n1ï¸âƒ£ Hard Voting Ensemble (Majority Vote)\")\n",
    "hard_voting = VotingEnsemble(model_list, device, voting='hard')\n",
    "preds, labels, acc = hard_voting.predict(test_loader)\n",
    "ensemble_results['Hard Voting'] = acc\n",
    "print(f\"   âœ… Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "# 2. Soft Voting Ensemble\n",
    "print(\"\\n2ï¸âƒ£ Soft Voting Ensemble (Average Probabilities)\")\n",
    "soft_voting = VotingEnsemble(model_list, device, voting='soft')\n",
    "preds, labels, acc = soft_voting.predict(test_loader)\n",
    "ensemble_results['Soft Voting'] = acc\n",
    "print(f\"   âœ… Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "# 3. Weighted Ensemble (based on validation accuracy)\n",
    "print(\"\\n3ï¸âƒ£ Weighted Ensemble (Performance-based)\")\n",
    "weights = [val_accuracies[name] for name in trained_models.keys()]\n",
    "weighted_ensemble = WeightedEnsemble(model_list, weights, device)\n",
    "preds, labels, acc = weighted_ensemble.predict(test_loader)\n",
    "ensemble_results['Weighted (Val Acc)'] = acc\n",
    "print(f\"   âœ… Test Accuracy: {acc:.2f}%\")\n",
    "print(f\"   Weights: {[f'{w:.3f}' for w in weighted_ensemble.weights]}\")\n",
    "\n",
    "# 4. Stacking Ensemble with Random Forest\n",
    "print(\"\\n4ï¸âƒ£ Stacking Ensemble (Random Forest Meta-Classifier)\")\n",
    "rf_meta = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "stacking_rf = StackingEnsemble(model_list, rf_meta, device)\n",
    "stacking_rf.fit(train_loader, val_loader)\n",
    "preds, labels, acc = stacking_rf.predict(test_loader)\n",
    "ensemble_results['Stacking (RF)'] = acc\n",
    "print(f\"   âœ… Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "# 5. Stacking Ensemble with Logistic Regression\n",
    "print(\"\\n5ï¸âƒ£ Stacking Ensemble (Logistic Regression Meta-Classifier)\")\n",
    "lr_meta = LogisticRegression(random_state=42, max_iter=1000)\n",
    "stacking_lr = StackingEnsemble(model_list, lr_meta, device)\n",
    "stacking_lr.fit(train_loader, val_loader)\n",
    "preds, labels, acc = stacking_lr.predict(test_loader)\n",
    "ensemble_results['Stacking (LR)'] = acc\n",
    "print(f\"   âœ… Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“Š ENSEMBLE RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nðŸ† Individual Model Performances (Validation):\")\n",
    "for name, acc in sorted(val_accuracies.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {name}: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Ensemble Performances (Test):\")\n",
    "for name, acc in sorted(ensemble_results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {name}: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\nðŸŽ–ï¸  Best Method: \", max(ensemble_results, key=ensemble_results.get))\n",
    "print(f\"ðŸŽ–ï¸  Best Accuracy: {max(ensemble_results.values()):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2817f1",
   "metadata": {},
   "source": [
    "# ðŸ“Š Visualization & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73920b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of all methods\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Individual models\n",
    "ax1 = axes[0]\n",
    "names = list(val_accuracies.keys())\n",
    "accs = list(val_accuracies.values())\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(names)))\n",
    "\n",
    "bars1 = ax1.bar(names, accs, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax1.set_title('Individual Model Performance (Validation)', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Model', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax1.set_ylim([min(accs) - 2, 100])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.2f}%',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Ensemble methods\n",
    "ax2 = axes[1]\n",
    "ens_names = list(ensemble_results.keys())\n",
    "ens_accs = list(ensemble_results.values())\n",
    "colors2 = plt.cm.plasma(np.linspace(0, 1, len(ens_names)))\n",
    "\n",
    "bars2 = ax2.bar(ens_names, ens_accs, color=colors2, alpha=0.8, edgecolor='black')\n",
    "ax2.set_title('Ensemble Performance (Test)', fontsize=16, fontweight='bold')\n",
    "ax2.set_xlabel('Ensemble Method', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_ylim([min(ens_accs) - 2, 100])\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.2f}%',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add horizontal line at 98% target\n",
    "for ax in axes:\n",
    "    ax.axhline(y=98, color='red', linestyle='--', linewidth=2, label='Target (98%)', alpha=0.7)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ensemble_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Plot saved as 'ensemble_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (model_name, history) in enumerate(histories.items()):\n",
    "    if idx >= 6:\n",
    "        break\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    epochs = range(1, len(history['train_acc']) + 1)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax.plot(epochs, history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "    ax.plot(epochs, history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "    \n",
    "    ax.set_title(f'{model_name} - Training History', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch', fontsize=11)\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=11)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([50, 100])\n",
    "\n",
    "# Hide extra subplot if any\n",
    "for idx in range(len(histories), 6):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_histories.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Training history plot saved as 'training_histories.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84754264",
   "metadata": {},
   "source": [
    "# ðŸ’¾ Save Final Results & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48105f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble models\n",
    "import pickle\n",
    "\n",
    "print(\"ðŸ’¾ Saving ensemble models...\")\n",
    "\n",
    "# Save stacking ensemble\n",
    "with open('stacking_rf_ensemble.pkl', 'wb') as f:\n",
    "    pickle.dump(stacking_rf, f)\n",
    "print(\"   âœ… Saved Stacking (RF) ensemble\")\n",
    "\n",
    "with open('stacking_lr_ensemble.pkl', 'wb') as f:\n",
    "    pickle.dump(stacking_lr, f)\n",
    "print(\"   âœ… Saved Stacking (LR) ensemble\")\n",
    "\n",
    "# Save results summary\n",
    "results_summary = {\n",
    "    'individual_models': val_accuracies,\n",
    "    'ensemble_methods': ensemble_results,\n",
    "    'best_method': max(ensemble_results, key=ensemble_results.get),\n",
    "    'best_accuracy': max(ensemble_results.values()),\n",
    "    'training_configs': training_config\n",
    "}\n",
    "\n",
    "with open('ensemble_results_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(results_summary, f)\n",
    "print(\"   âœ… Saved results summary\")\n",
    "\n",
    "# Create a detailed report\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "ðŸ† LUNG CANCER CLASSIFICATION - ENSEMBLE LEARNING RESULTS\n",
    "{'='*80}\n",
    "\n",
    "ðŸ“Š INDIVIDUAL MODEL PERFORMANCES (Validation Set):\n",
    "{'-'*80}\n",
    "\"\"\"\n",
    "\n",
    "for name, acc in sorted(val_accuracies.items(), key=lambda x: x[1], reverse=True):\n",
    "    report += f\"   {name:20s}: {acc:6.2f}%\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "{'-'*80}\n",
    "ðŸŽ¯ ENSEMBLE METHOD PERFORMANCES (Test Set):\n",
    "{'-'*80}\n",
    "\"\"\"\n",
    "\n",
    "for name, acc in sorted(ensemble_results.items(), key=lambda x: x[1], reverse=True):\n",
    "    report += f\"   {name:25s}: {acc:6.2f}%\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "{'-'*80}\n",
    "ðŸŽ–ï¸  BEST PERFORMING METHOD:\n",
    "   Method: {max(ensemble_results, key=ensemble_results.get)}\n",
    "   Accuracy: {max(ensemble_results.values()):.2f}%\n",
    "   \n",
    "ðŸŽ¯ TARGET ACHIEVEMENT:\n",
    "   Target: 98.00%\n",
    "   Achieved: {max(ensemble_results.values()):.2f}%\n",
    "   Status: {'âœ… TARGET ACHIEVED!' if max(ensemble_results.values()) >= 98.0 else 'âš ï¸ CLOSE TO TARGET'}\n",
    "\n",
    "{'-'*80}\n",
    "ðŸ“ˆ KEY INSIGHTS:\n",
    "   â€¢ CNN Baseline: {val_accuracies.get('CNN', 0):.2f}% (98.83% in original)\n",
    "   â€¢ Best Individual: {max(val_accuracies.values()):.2f}%\n",
    "   â€¢ Best Ensemble: {max(ensemble_results.values()):.2f}%\n",
    "   â€¢ Improvement: {max(ensemble_results.values()) - max(val_accuracies.values()):.2f}%\n",
    "\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report to file\n",
    "with open('ensemble_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "print(\"âœ… Saved detailed report to 'ensemble_report.txt'\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab469de6",
   "metadata": {},
   "source": [
    "# ðŸ“ Quick Guide: How to Use This Notebook\n",
    "\n",
    "## ðŸš€ Step-by-Step Execution:\n",
    "\n",
    "1. **Setup & Data Loading** (Cells 1-11)\n",
    "   - Run all cells to load libraries, configure paths, and load datasets\n",
    "   \n",
    "2. **Model Definitions** (Cells 12-16)\n",
    "   - Define all 5 model architectures (CNN, ResNet18, ResNet50, VGG16, InceptionV3)\n",
    "   \n",
    "3. **Training** (Cells 17-19) â° **~2-3 hours**\n",
    "   - Initialize all models\n",
    "   - Train each model with early stopping\n",
    "   - Models are saved automatically\n",
    "   \n",
    "4. **Ensemble Evaluation** (Cell 20)\n",
    "   - Test all ensemble methods\n",
    "   - Compare performances\n",
    "   \n",
    "5. **Visualization** (Cells 21-22)\n",
    "   - Generate comparison plots\n",
    "   - View training histories\n",
    "   \n",
    "6. **Save Results** (Cell 23)\n",
    "   - Save trained models and reports\n",
    "\n",
    "## ðŸŽ¯ Expected Results:\n",
    "\n",
    "- **Individual Models:** 95-98% accuracy\n",
    "- **Ensemble Methods:** >98% accuracy (target achieved!)\n",
    "- **Best Method:** Likely Soft Voting or Stacking\n",
    "\n",
    "## ðŸ’¡ Tips:\n",
    "\n",
    "- **GPU Required:** Training will be slow on CPU\n",
    "- **Memory:** If OOM error, reduce batch size to 16\n",
    "- **Time Saving:** You can train models separately (comment out some models)\n",
    "- **Quick Test:** Use fewer epochs (change to 5) for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b8e4c",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Optional: Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions from best ensemble method\n",
    "print(\"ðŸ“Š Generating detailed metrics for best ensemble...\")\n",
    "\n",
    "# Use the best ensemble (adjust based on your results)\n",
    "best_ensemble = soft_voting  # or stacking_rf, weighted_ensemble, etc.\n",
    "preds, labels, acc = best_ensemble.predict(test_loader)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=train_dataset.classes,\n",
    "            yticklabels=train_dataset.classes,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Best Ensemble', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_ensemble.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“‹ CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(labels, preds, \n",
    "                           target_names=train_dataset.classes,\n",
    "                           digits=4))\n",
    "\n",
    "# Calculate additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "precision = precision_score(labels, preds, average='weighted')\n",
    "recall = recall_score(labels, preds, average='weighted')\n",
    "f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š DETAILED METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   Accuracy:  {acc:.4f}%\")\n",
    "print(f\"   Precision: {precision:.4f}\")\n",
    "print(f\"   Recall:    {recall:.4f}\")\n",
    "print(f\"   F1-Score:  {f1:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ… Detailed analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
