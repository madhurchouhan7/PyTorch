{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba87b85",
   "metadata": {},
   "source": [
    "# **Dataset and Dataloaders Classes In PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff0606",
   "metadata": {},
   "source": [
    "#### **What is Batch Gradient Descent?**\n",
    "- **The Rule**: It calculates the error for every single example in your entire dataset before making just one update to the model's weights.\n",
    "- **The Analogy**: It is like a teacher grading 1,000 exam papers and calculating the class average before deciding to change their teaching style once.\n",
    "- **The Math**: It takes the \"average direction\" of all data points combined, creating a very smooth path down the loss mountain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19f717",
   "metadata": {},
   "source": [
    "#### **The 3 Major Problems (Why we don't use it for Images)**\n",
    "1. **Memory Crash (RAM/GPU):** To calculate the gradient for the whole dataset at once, the computer must load all 5,000+ images into memory simultaneously. This is impossible for large datasets and causes Out of Memory errors immediately.\n",
    "\n",
    "2. **Too Slow to Learn:** Since it processes the whole dataset for just one step, it learns very slowly. If you have 10,000 images, you wait for 10,000 calculations just to move the weights slightly. Mini-batch would have moved the weights ~300 times in that same period.\n",
    "\n",
    "3. **Gets Stuck (Saddle Points):** Because it calculates the \"perfect\" average, it moves too smoothly. If it hits a flat area (saddle point) or a small hole (local minimum), it stops. It lacks the \"random noise\" of Stochastic Gradient Descent that helps jiggle the model out of these traps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef015a30",
   "metadata": {},
   "source": [
    "### **Mini-Batch Gradient Descent**\n",
    "- The Concept: Instead of processing the entire dataset (Batch GD) or just one example (Stochastic GD), the model processes data in small groups called Batches (e.g., 32 or 64 images).\n",
    "- The Standard: This is the default algorithm used for almost all Deep Learning tasks today\n",
    "\n",
    "#### **Why we use it? (3 Main Advantages)**\n",
    "- **Prevents Memory Crashes:** It is impossible to load 10,000 high-res medical images into GPU memory at once. Mini-batch only loads 32 images at a time, making it efficient for limited VRAM.\n",
    "\n",
    "- **Faster Learning (Vectorization):** GPUs are designed for parallel math. Processing 32 images at once is mathematically just as fast as processing 1 image, so you get 32x more work done per step.\n",
    "\n",
    "- **Escapes \"Saddle Points\" (Traps):** Batch GD moves too smoothly and often gets stuck in flat areas (saddle points) where the error stops decreasing.\n",
    "\n",
    "Mini-batch introduces slight noise (randomness) because every batch is different. This \"jitter\" helps the model shake itself out of these traps and find the true solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a309b",
   "metadata": {},
   "source": [
    "**DATASET and DATALOADER are core abstractions in PyTorch that decouple how you define your data from how you efficiently interate over it in training loop.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27dc1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123952af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "                            n_samples=10, # Total rows of data\n",
    "                            n_features=2, # Columns (inputs)\n",
    "                            n_classes=2,   # output \n",
    "                            n_informative=2,  # Feature that acutally help predict the output\n",
    "                            n_redundant=0,    # uselesss noise features\n",
    "                            random_state=42  # Seeds the random number generator so you get the same numbers every time\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2f28c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06833894, -0.97007347],\n",
       "       [-1.14021544, -0.83879234],\n",
       "       [-2.8953973 ,  1.97686236],\n",
       "       [-0.72063436, -0.96059253],\n",
       "       [-1.96287438, -0.99225135],\n",
       "       [-0.9382051 , -0.54304815],\n",
       "       [ 1.72725924, -1.18582677],\n",
       "       [ 1.77736657,  1.51157598],\n",
       "       [ 1.89969252,  0.83444483],\n",
       "       [-0.58723065, -1.97171753]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50b8d754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c70ea6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa8a3278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adb80b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into tensors\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0168423c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0683, -0.9701],\n",
       "        [-1.1402, -0.8388],\n",
       "        [-2.8954,  1.9769],\n",
       "        [-0.7206, -0.9606],\n",
       "        [-1.9629, -0.9923],\n",
       "        [-0.9382, -0.5430],\n",
       "        [ 1.7273, -1.1858],\n",
       "        [ 1.7774,  1.5116],\n",
       "        [ 1.8997,  0.8344],\n",
       "        [-0.5872, -1.9717]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a1ccfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fd7c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4715811",
   "metadata": {},
   "source": [
    "### 1. Generating Fake Data \n",
    "- What: Creates a synthetic (fake) dataset using Scikit-Learn.\n",
    "\n",
    "- Why: Useful for testing code when you don't have a real CSV file yet.\n",
    "\n",
    "- Key Variables:\n",
    "\n",
    "    - X (Features): The input data (e.g., Patient Age, BP). Shape is (10, 2) → 10 rows, 2 columns.\n",
    "\n",
    "    - y (Labels): The target answers (e.g., 0=Healthy, 1=Sick). Shape is (10,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    # 2. THE LENGTH\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    # 3. THE FETCHER (The Magic Method)\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9861d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93135e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96de4de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.8954,  1.9769]), tensor(0))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "451e9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3b4aec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Features:\n",
      " tensor([[ 1.0683, -0.9701],\n",
      "        [ 1.8997,  0.8344]])\n",
      "Batch Labels:\n",
      " tensor([1, 1])\n",
      "------------------------------\n",
      "Batch Features:\n",
      " tensor([[-1.1402, -0.8388],\n",
      "        [ 1.7774,  1.5116]])\n",
      "Batch Labels:\n",
      " tensor([0, 1])\n",
      "------------------------------\n",
      "Batch Features:\n",
      " tensor([[-1.9629, -0.9923],\n",
      "        [ 1.7273, -1.1858]])\n",
      "Batch Labels:\n",
      " tensor([0, 1])\n",
      "------------------------------\n",
      "Batch Features:\n",
      " tensor([[-0.7206, -0.9606],\n",
      "        [-2.8954,  1.9769]])\n",
      "Batch Labels:\n",
      " tensor([0, 0])\n",
      "------------------------------\n",
      "Batch Features:\n",
      " tensor([[-0.9382, -0.5430],\n",
      "        [-0.5872, -1.9717]])\n",
      "Batch Labels:\n",
      " tensor([1, 0])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for batch_features, batch_labels in dataloader:\n",
    "    print(\"Batch Features:\\n\", batch_features)\n",
    "    print(\"Batch Labels:\\n\", batch_labels)\n",
    "    print(\"-\"*30)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5968672",
   "metadata": {},
   "source": [
    "1. Generating Fake Data (make_classification)\n",
    "What: Creates a synthetic (fake) dataset using Scikit-Learn.\n",
    "\n",
    "Why: Useful for testing code when you don't have a real CSV file yet.\n",
    "\n",
    "Key Variables:\n",
    "\n",
    "X (Features): The input data (e.g., Patient Age, BP). Shape is (10, 2) → 10 rows, 2 columns.\n",
    "\n",
    "y (Labels): The target answers (e.g., 0=Healthy, 1=Sick). Shape is (10,).\n",
    "\n",
    "2. Converting to TensorsConcept: PyTorch cannot read NumPy arrays; it only understands Tensors.Crucial Rule for Data Types:X must be float32: Neural networks do math with decimals (weights $\\times$ inputs). If you leave it as float64 (NumPy default), PyTorch will error out.y must be long (int64): Class labels (Category 0, Category 1) must be integers. Loss functions (like CrossEntropy) expect integers, not decimals.\n",
    "\n",
    "3. The CustomDataset Class (The \"Bookshelf\")\n",
    "Concept: This class standardizes how your data is stored and accessed. It doesn't load data into the model; it just sits there waiting to be asked for data.\n",
    "\n",
    "The 3 Required Methods:\n",
    "\n",
    "__init__ (The Setup): Runs once. You store your data (tensors) inside self variables here.\n",
    "\n",
    "__len__ (The Count): Tells PyTorch the total size of the dataset (e.g., \"I have 10 rows\").\n",
    "\n",
    "__getitem__ (The Grabber): The most important part. It tells PyTorch: \"When I ask for item idx, give me the Feature and Label at that index.\"\n",
    "\n",
    "4. The DataLoader (The \"Delivery Truck\")\n",
    "Concept: The Dataset sits on the shelf. The DataLoader is the worker that grabs items, packages them, and delivers them to the model.\n",
    "\n",
    "batch_size=2: Instead of feeding the model 1 row at a time (too slow) or all 10 rows (crashes RAM), we feed 2 rows at a time.\n",
    "\n",
    "shuffle=True: Crucial. It shuffles the data before every epoch.\n",
    "\n",
    "Why? If data is sorted (e.g., all \"Cancer\" cases first), the model learns the order, not the pattern. Shuffling breaks this bias.\n",
    "\n",
    "5. The Training Loop\n",
    "Action: for batch_features, batch_labels in dataloader:\n",
    "\n",
    "What happens here:\n",
    "\n",
    "The loader randomly picks 2 indices (e.g., Index 3 and Index 8).\n",
    "\n",
    "It uses __getitem__ to fetch those 2 specific rows.\n",
    "\n",
    "It stacks them together into a single batch.\n",
    "\n",
    "Result: You get a Tensor of shape (2, 2) (2 samples, 2 features) ready for the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623d9cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
