{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe81b78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[0;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzaidworks0508/cow-breed-classification-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"zaidworks0508/cow-breed-classification-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Speed/throughput knobs\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb10eb",
   "metadata": {},
   "source": [
    "# Cattle Breed Classification - Comparative Study\n",
    "\n",
    "This notebook compares three CNN architectures for cattle breed classification:\n",
    "1. ResNet18\n",
    "2. ResNet50\n",
    "3. EfficientNetB1\n",
    "\n",
    "Using the zaidworks0508/cow-breed-classification-dataset with transfer learning approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5712a6",
   "metadata": {},
   "source": [
    "## Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the downloaded dataset structure\n",
    "print(f\"Base path: {path}\")\n",
    "print(\"\\nExploring directory structure...\")\n",
    "\n",
    "def explore_directory(dir_path, max_depth=3, current_depth=0, prefix=\"\"):\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    try:\n",
    "        items = os.listdir(dir_path)\n",
    "        for item in items[:10]:  # Limit to first 10 items per directory\n",
    "            item_path = os.path.join(dir_path, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                print(f\"{prefix}üìÅ {item}/\")\n",
    "                explore_directory(item_path, max_depth, current_depth + 1, prefix + \"  \")\n",
    "            else:\n",
    "                print(f\"{prefix}üìÑ {item}\")\n",
    "    except PermissionError:\n",
    "        print(f\"{prefix}‚ùå Permission denied\")\n",
    "    except Exception as e:\n",
    "        print(f\"{prefix}‚ùå Error: {e}\")\n",
    "\n",
    "explore_directory(path, max_depth=4)\n",
    "\n",
    "# Find the dataset path\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Searching for cattle breed images...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataset_path = None\n",
    "for root, dirs, files in os.walk(path):\n",
    "    if any(item.endswith(('.jpg', '.jpeg', '.png')) for item in files):\n",
    "        dataset_path = root\n",
    "        print(f\"‚úÖ Found images at: {dataset_path}\")\n",
    "        break\n",
    "\n",
    "if dataset_path is None:\n",
    "    dataset_path = path\n",
    "    print(f\"Using base path as dataset path: {dataset_path}\")\n",
    "\n",
    "# List classes and count images\n",
    "classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "print(f\"\\nüìä Cattle breeds found: {sorted(classes)}\")\n",
    "\n",
    "print(\"\\nüìà Image counts per breed:\")\n",
    "total_images = 0\n",
    "for cls in sorted(classes):\n",
    "    cls_path = os.path.join(dataset_path, cls)\n",
    "    try:\n",
    "        num_images = len([f for f in os.listdir(cls_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        print(f\"  {cls}: {num_images:,} images\")\n",
    "        total_images += num_images\n",
    "    except Exception as e:\n",
    "        print(f\"  {cls}: Error - {e}\")\n",
    "\n",
    "print(f\"\\n  Total images: {total_images:,}\")\n",
    "print(f\"  Total breeds: {len(classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = 224  # Consider 256 if GPU allows; 224 keeps speed high\n",
    "BATCH_SIZE = 48  # Drop to 32 if OOM\n",
    "EPOCHS = 25\n",
    "WARMUP_EPOCHS = 3  # Train head-only before unfreezing last block\n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Custom Dataset class\n",
    "class CattleDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        # Get class directories\n",
    "        classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_names = classes\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "        # Load all image paths and labels\n",
    "        for cls in classes:\n",
    "            cls_path = os.path.join(root_dir, cls)\n",
    "            cls_idx = self.class_to_idx[cls]\n",
    "            for img_name in os.listdir(cls_path):\n",
    "                if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    self.images.append(os.path.join(cls_path, img_name))\n",
    "                    self.labels.append(cls_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Data augmentation and preprocessing for training (balanced, not too heavy)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(p=0.1),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Only normalization for validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = CattleDataset(dataset_path, transform=None)\n",
    "class_names = full_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Total images: {len(full_dataset)}\")\n",
    "\n",
    "# Split dataset into train and validation\n",
    "from torch.utils.data import random_split\n",
    "train_size = int((1 - VALIDATION_SPLIT) * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_indices, val_indices = torch.utils.data.random_split(\n",
    "    range(len(full_dataset)),\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Create separate datasets with different transforms\n",
    "class SubsetDataset(Dataset):\n",
    "    def __init__(self, dataset, indices, transform):\n",
    "        self.dataset = dataset\n",
    "        self.indices = list(indices)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = self.indices[idx]\n",
    "        img_path = self.dataset.images[original_idx]\n",
    "        label = self.dataset.labels[original_idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "train_dataset = SubsetDataset(full_dataset, train_indices, train_transform)\n",
    "val_dataset = SubsetDataset(full_dataset, val_indices, val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Batches per epoch (train): {len(train_loader)}\")\n",
    "print(f\"Batches per epoch (val): {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc5927",
   "metadata": {},
   "source": [
    "## Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daafb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Denormalization for display\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "for i in range(min(9, len(images))):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "\n",
    "    # Convert tensor to image\n",
    "    img = images[i]\n",
    "    img = inv_normalize(img)\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[labels[i].item()])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e93fa3",
   "metadata": {},
   "source": [
    "## Training Infrastructure: Early Stopping & Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping implementation\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=6, min_delta=0, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "\n",
    "# GradScaler for mixed precision\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "\n",
    "def unfreeze_last_block(model, model_name):\n",
    "    \"\"\"Unfreeze final block to fine-tune after warmup.\"\"\"\n",
    "    if model_name in [\"ResNet18\", \"ResNet50\"]:\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"layer4\" in name:\n",
    "                param.requires_grad = True\n",
    "    elif model_name == \"EfficientNetB1\":\n",
    "        unfreeze = False\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"features.6\" in name or \"features.7\" in name:\n",
    "                unfreeze = True\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, model_name):\n",
    "    \"\"\"Train with warmup, AMP, cosine LR, early stopping, and selective unfreeze.\"\"\"\n",
    "\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "    early_stopping = EarlyStopping(patience=6, verbose=True)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # After warmup, unfreeze last block and reset optimizer on trainable params\n",
    "        if epoch == WARMUP_EPOCHS:\n",
    "            unfreeze_last_block(model, model_name)\n",
    "            optimizer = optim.AdamW(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                lr=LEARNING_RATE * 0.5,\n",
    "                weight_decay=WEIGHT_DECAY\n",
    "            )\n",
    "            print(f\"Unfroze last block of {model_name} and reset optimizer\")\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            train_pbar.set_postfix({\n",
    "                'loss': f'{train_loss/len(train_loader):.4f}',\n",
    "                'acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]  ')\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                val_pbar.set_postfix({\n",
    "                    'loss': f'{val_loss/len(val_loader):.4f}',\n",
    "                    'acc': f'{100.*val_correct/val_total:.2f}%'\n",
    "                })\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_accuracy)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_accuracy)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "        print(f'  Learning Rate: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\nEarly stopping triggered!\")\n",
    "            model.load_state_dict(early_stopping.best_model)\n",
    "            break\n",
    "\n",
    "    if early_stopping.best_model is not None:\n",
    "        model.load_state_dict(early_stopping.best_model)\n",
    "        print(\"\\nRestored best model weights\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f908eb",
   "metadata": {},
   "source": [
    "## Model 1: ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet18 model\n",
    "def build_resnet18_model(num_classes=3):\n",
    "    \"\"\"Build ResNet18 model with frozen base and custom classifier\"\"\"\n",
    "\n",
    "    # Load pre-trained ResNet18\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace final fully connected layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "resnet18_model = build_resnet18_model(num_classes=num_classes)\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"ResNet18 Model Architecture:\")\n",
    "print(\"=\"*70)\n",
    "print(resnet18_model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in resnet18_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in resnet18_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c27d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet18 (head first, backbone frozen; fine-tune later via unfreeze)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "optimizer_resnet18 = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, resnet18_model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "history_resnet18 = train_model(\n",
    "    resnet18_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_resnet18,\n",
    "    EPOCHS,\n",
    "    \"ResNet18\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e6287",
   "metadata": {},
   "source": [
    "## Model 2: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet50 model\n",
    "def build_resnet50_model(num_classes=3):\n",
    "    \"\"\"Build ResNet50 model with frozen base and custom classifier\"\"\"\n",
    "\n",
    "    # Load pre-trained ResNet50\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace final fully connected layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "resnet50_model = build_resnet50_model(num_classes=num_classes)\n",
    "resnet50_model = resnet50_model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"ResNet50 Model Architecture:\")\n",
    "print(\"=\"*70)\n",
    "print(resnet50_model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in resnet50_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in resnet50_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0811d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet50\n",
    "optimizer_resnet50 = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, resnet50_model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "history_resnet50 = train_model(\n",
    "    resnet50_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_resnet50,\n",
    "    EPOCHS,\n",
    "    \"ResNet50\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce220f",
   "metadata": {},
   "source": [
    "## Model 3: EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd74e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build EfficientNetB1 model\n",
    "def build_efficientnet_model(num_classes=3):\n",
    "    \"\"\"Build EfficientNet-B1 model with frozen base and custom classifier\"\"\"\n",
    "\n",
    "    # Load pre-trained EfficientNet-B1\n",
    "    model = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace classifier with custom layers\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "efficientnet_model = build_efficientnet_model(num_classes=num_classes)\n",
    "efficientnet_model = efficientnet_model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"EfficientNetB1 Model Architecture:\")\n",
    "print(\"=\"*70)\n",
    "print(efficientnet_model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in efficientnet_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in efficientnet_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EfficientNetB1\n",
    "optimizer_efficientnet = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, efficientnet_model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "history_efficientnet = train_model(\n",
    "    efficientnet_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_efficientnet,\n",
    "    EPOCHS,\n",
    "    \"EfficientNetB1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ade9f",
   "metadata": {},
   "source": [
    "## Model 4: InceptionV4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eab619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build InceptionV4 model\n",
    "def build_inception_model(num_classes=3):\n",
    "    \"\"\"Build InceptionV4 model with frozen base and custom classifier\"\"\"\n",
    "\n",
    "    # Load pre-trained InceptionV3 (V4 not directly available; V3 is excellent alternative)\n",
    "    model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace final fully connected layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "inception_model = build_inception_model(num_classes=num_classes)\n",
    "inception_model = inception_model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"InceptionV3 Model Architecture:\")\n",
    "print(\"=\"*70)\n",
    "print(inception_model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in inception_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in inception_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec59ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train InceptionV3\n",
    "optimizer_inception = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, inception_model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "history_inception = train_model(\n",
    "    inception_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_inception,\n",
    "    EPOCHS,\n",
    "    \"InceptionV3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7c23a",
   "metadata": {},
   "source": [
    "## Model 5: Vision Transformer (ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f159e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vision Transformer (ViT) model\n",
    "def build_vit_model(num_classes=3):\n",
    "    \"\"\"Build Vision Transformer model with frozen base and custom classifier\"\"\"\n",
    "\n",
    "    # Load pre-trained ViT-B/16\n",
    "    model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace final classification head\n",
    "    num_features = model.heads[0].in_features\n",
    "    model.heads = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "vit_model = build_vit_model(num_classes=num_classes)\n",
    "vit_model = vit_model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"Vision Transformer (ViT-B/16) Model Architecture:\")\n",
    "print(\"=\"*70)\n",
    "print(vit_model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in vit_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in vit_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Vision Transformer\n",
    "optimizer_vit = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, vit_model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "history_vit = train_model(\n",
    "    vit_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_vit,\n",
    "    EPOCHS,\n",
    "    \"ViT-B/16\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f584b",
   "metadata": {},
   "source": [
    "### InceptionV3 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_inception, \"InceptionV3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db479db",
   "metadata": {},
   "source": [
    "### Vision Transformer (ViT) Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_vit, \"ViT-B/16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8623c5",
   "metadata": {},
   "source": [
    "## Grad-CAM: Visualize Model Attention Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf23571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM Implementation for model interpretability\n",
    "class GradCAM:\n",
    "    \"\"\"Generate Grad-CAM heatmaps to visualize where model attends\"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Register hooks\n",
    "        self.target_layer.register_full_backward_hook(self.save_gradients)\n",
    "        self.target_layer.register_forward_hook(self.save_activations)\n",
    "    \n",
    "    def save_activations(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def save_gradients(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def generate_cam(self, input_tensor, class_idx=None):\n",
    "        \"\"\"Generate CAM for input tensor\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.enable_grad():\n",
    "            output = self.model(input_tensor)\n",
    "            if class_idx is None:\n",
    "                class_idx = output.argmax(dim=1)\n",
    "            \n",
    "            self.model.zero_grad()\n",
    "            target_score = output[0, class_idx]\n",
    "            target_score.backward()\n",
    "        \n",
    "        # Compute CAM\n",
    "        gradients = self.gradients[0].cpu()\n",
    "        activations = self.activations[0].cpu()\n",
    "        \n",
    "        weights = gradients.mean(dim=(1, 2))\n",
    "        cam = (weights.view(-1, 1, 1) * activations).sum(dim=0)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        \n",
    "        return cam.numpy()\n",
    "\n",
    "\n",
    "def visualize_grad_cam(model, data_loader, model_name, num_samples=3):\n",
    "    \"\"\"Visualize Grad-CAM heatmaps for model predictions\"\"\"\n",
    "    print(f\"\\nGenerating Grad-CAM visualizations for {model_name}...\")\n",
    "    \n",
    "    # Get target layer based on model type\n",
    "    if \"ResNet\" in model_name:\n",
    "        target_layer = model.layer4[-1].conv2\n",
    "    elif \"EfficientNet\" in model_name:\n",
    "        target_layer = model.features[-1]\n",
    "    elif \"InceptionV3\" in model_name:\n",
    "        target_layer = model.Mixed_7c\n",
    "    elif \"ViT\" in model_name:\n",
    "        target_layer = model.encoder.layers.encoder_layer_11\n",
    "    \n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "    \n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    sample_count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            if sample_count >= num_samples:\n",
    "                break\n",
    "            \n",
    "            for i in range(len(inputs)):\n",
    "                if sample_count >= num_samples:\n",
    "                    break\n",
    "                \n",
    "                input_img = inputs[i].unsqueeze(0).to(device)\n",
    "                label = labels[i].item()\n",
    "                \n",
    "                # Generate prediction and CAM\n",
    "                with torch.enable_grad():\n",
    "                    output = model(input_img)\n",
    "                    pred_class = output.argmax(dim=1).item()\n",
    "                    confidence = torch.softmax(output, dim=1)[0, pred_class].item()\n",
    "                \n",
    "                cam = grad_cam.generate_cam(input_img, pred_class)\n",
    "                \n",
    "                # Denormalize image\n",
    "                img_np = inputs[i].cpu().numpy()\n",
    "                img_np = np.transpose(img_np, (1, 2, 0))\n",
    "                img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-8)\n",
    "                \n",
    "                # Overlay CAM on image\n",
    "                cam_resized = cv2.resize(cam, (img_np.shape[1], img_np.shape[0]))\n",
    "                cam_heatmap = plt.cm.jet(cam_resized)[:, :, :3]\n",
    "                overlay = 0.6 * img_np + 0.4 * cam_heatmap\n",
    "                \n",
    "                # Plot\n",
    "                axes[sample_count, 0].imshow(img_np)\n",
    "                axes[sample_count, 0].set_title(f\"Original\\n{class_names[label]}\")\n",
    "                axes[sample_count, 0].axis('off')\n",
    "                \n",
    "                axes[sample_count, 1].imshow(cam_resized, cmap='jet')\n",
    "                axes[sample_count, 1].set_title(\"Grad-CAM Heatmap\")\n",
    "                axes[sample_count, 1].axis('off')\n",
    "                \n",
    "                axes[sample_count, 2].imshow(overlay)\n",
    "                axes[sample_count, 2].set_title(f\"Pred: {class_names[pred_class]}\\nConf: {confidence:.2%}\")\n",
    "                axes[sample_count, 2].axis('off')\n",
    "                \n",
    "                sample_count += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Import cv2 for CAM resizing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f82d0",
   "metadata": {},
   "source": [
    "## Evaluation: Confusion Matrix, Classification Report, and Macro F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc308356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated evaluation function with Macro F1-Score and Grad-CAM\n",
    "def evaluate_model(model, model_name, data_loader, show_gradcam=True):\n",
    "    \"\"\"Evaluate model: precision, recall, weighted F1, macro F1, and confusion matrix\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_preds)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = np.mean(y_pred == y_true)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(f\"\\nOverall Metrics:\")\n",
    "    print(f\"Accuracy:           {accuracy:.4f}\")\n",
    "    print(f\"Weighted Precision: {precision:.4f}\")\n",
    "    print(f\"Weighted Recall:    {recall:.4f}\")\n",
    "    print(f\"Weighted F1-Score:  {f1_weighted:.4f}\")\n",
    "    print(f\"üéØ Macro F1-Score:  {f1_macro:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'{model_name} - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Grad-CAM visualization\n",
    "    if show_gradcam:\n",
    "        try:\n",
    "            visualize_grad_cam(model, data_loader, model_name, num_samples=3)\n",
    "        except Exception as e:\n",
    "            print(f\"Note: Grad-CAM visualization skipped for {model_name}: {str(e)}\")\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_macro': f1_macro\n",
    "    }\n",
    "\n",
    "# Evaluate all models\n",
    "metrics_resnet18 = evaluate_model(resnet18_model, \"ResNet18\", val_loader)\n",
    "metrics_resnet50 = evaluate_model(resnet50_model, \"ResNet50\", val_loader)\n",
    "metrics_efficientnet = evaluate_model(efficientnet_model, \"EfficientNetB1\", val_loader)\n",
    "metrics_inception = evaluate_model(inception_model, \"InceptionV3\", val_loader)\n",
    "metrics_vit = evaluate_model(vit_model, \"ViT-B/16\", val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison dataframe with Macro F1-Score\n",
    "comparison_data = {\n",
    "    'Model': ['ResNet18', 'ResNet50', 'EfficientNetB1', 'InceptionV3', 'ViT-B/16'],\n",
    "    'Accuracy': [\n",
    "        metrics_resnet18['accuracy'],\n",
    "        metrics_resnet50['accuracy'],\n",
    "        metrics_efficientnet['accuracy'],\n",
    "        metrics_inception['accuracy'],\n",
    "        metrics_vit['accuracy']\n",
    "    ],\n",
    "    'Precision': [\n",
    "        metrics_resnet18['precision'],\n",
    "        metrics_resnet50['precision'],\n",
    "        metrics_efficientnet['precision'],\n",
    "        metrics_inception['precision'],\n",
    "        metrics_vit['precision']\n",
    "    ],\n",
    "    'Recall': [\n",
    "        metrics_resnet18['recall'],\n",
    "        metrics_resnet50['recall'],\n",
    "        metrics_efficientnet['recall'],\n",
    "        metrics_inception['recall'],\n",
    "        metrics_vit['recall']\n",
    "    ],\n",
    "    'Weighted F1': [\n",
    "        metrics_resnet18['f1_weighted'],\n",
    "        metrics_resnet50['f1_weighted'],\n",
    "        metrics_efficientnet['f1_weighted'],\n",
    "        metrics_inception['f1_weighted'],\n",
    "        metrics_vit['f1_weighted']\n",
    "    ],\n",
    "    'üéØ Macro F1': [\n",
    "        metrics_resnet18['f1_macro'],\n",
    "        metrics_resnet50['f1_macro'],\n",
    "        metrics_efficientnet['f1_macro'],\n",
    "        metrics_inception['f1_macro'],\n",
    "        metrics_vit['f1_macro']\n",
    "    ],\n",
    "    'Best Val Acc': [\n",
    "        max(history_resnet18['val_acc']),\n",
    "        max(history_resnet50['val_acc']),\n",
    "        max(history_efficientnet['val_acc']),\n",
    "        max(history_inception['val_acc']),\n",
    "        max(history_vit['val_acc'])\n",
    "    ],\n",
    "    'Final Val Loss': [\n",
    "        history_resnet18['val_loss'][-1],\n",
    "        history_resnet50['val_loss'][-1],\n",
    "        history_efficientnet['val_loss'][-1],\n",
    "        history_inception['val_loss'][-1],\n",
    "        history_vit['val_loss'][-1]\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "print(\"FINAL MODEL COMPARISON SUMMARY - ALL 5 ARCHITECTURES\")\n",
    "print(\"=\"*110)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*110)\n",
    "\n",
    "# Highlight best models by different metrics\n",
    "best_accuracy_idx = comparison_df['Accuracy'].idxmax()\n",
    "best_macro_f1_idx = comparison_df['üéØ Macro F1'].idxmax()\n",
    "\n",
    "print(f\"\\nüèÜ Best by Accuracy: {comparison_df.loc[best_accuracy_idx, 'Model']}\")\n",
    "print(f\"   Accuracy: {comparison_df.loc[best_accuracy_idx, 'Accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ Best by Macro F1-Score: {comparison_df.loc[best_macro_f1_idx, 'Model']}\")\n",
    "print(f\"   Macro F1: {comparison_df.loc[best_macro_f1_idx, 'üéØ Macro F1']:.4f}\")\n",
    "print(f\"   Accuracy: {comparison_df.loc[best_macro_f1_idx, 'Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all models comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "models = comparison_df['Model'].tolist()\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#06A77D', '#D62839']\n",
    "\n",
    "# Accuracy Comparison\n",
    "axes[0, 0].bar(models, comparison_df['Accuracy'], color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[0, 0].set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0, 0].set_ylim([0.8, 1.0])\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(comparison_df['Accuracy']):\n",
    "    axes[0, 0].text(i, v, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Macro F1-Score Comparison\n",
    "axes[0, 1].bar(models, comparison_df['üéØ Macro F1'], color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[0, 1].set_title('üéØ Macro F1-Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Macro F1-Score', fontsize=12)\n",
    "axes[0, 1].set_ylim([0.8, 1.0])\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(comparison_df['üéØ Macro F1']):\n",
    "    axes[0, 1].text(i, v, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Weighted vs Macro F1-Score\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "axes[1, 0].bar(x - width/2, comparison_df['Weighted F1'], width, label='Weighted F1', color='skyblue', edgecolor='black')\n",
    "axes[1, 0].bar(x + width/2, comparison_df['üéØ Macro F1'], width, label='Macro F1', color='orange', edgecolor='black')\n",
    "axes[1, 0].set_title('Weighted vs Macro F1-Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('F1-Score', fontsize=12)\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(models, rotation=15)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "axes[1, 1].bar(x - width, comparison_df['Precision'], width, label='Precision', edgecolor='black')\n",
    "axes[1, 1].bar(x, comparison_df['Recall'], width, label='Recall', edgecolor='black')\n",
    "axes[1, 1].bar(x + width, comparison_df['Weighted F1'], width, label='Weighted F1', edgecolor='black')\n",
    "axes[1, 1].set_title('Precision, Recall, and Weighted F1 Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Score', fontsize=12)\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(models, rotation=15)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfab663",
   "metadata": {},
   "source": [
    "## Summary: Key Findings\n",
    "\n",
    "**Models Compared:**\n",
    "1. **ResNet18** - Lightweight, fast, good for real-time\n",
    "2. **ResNet50** - Deeper, more expressive than ResNet18\n",
    "3. **EfficientNetB1** - Parameter-efficient with strong scaling\n",
    "4. **InceptionV3** - Multi-scale feature extraction\n",
    "5. **Vision Transformer (ViT)** - State-of-the-art attention-based architecture\n",
    "\n",
    "**Key Metrics:**\n",
    "- **Accuracy**: Overall proportion of correct predictions\n",
    "- **Precision**: Fraction of positive predictions that are correct\n",
    "- **Recall**: Fraction of actual positives correctly identified\n",
    "- **Weighted F1-Score**: Harmonic mean of precision and recall (weighted by class support)\n",
    "- **üéØ Macro F1-Score**: Unweighted average F1 across all classes (treats all classes equally)\n",
    "\n",
    "**Grad-CAM Visualization:**\n",
    "Shows which regions the model focuses on for predictions. Red/orange regions are high-attention areas that strongly influence the model's decision.\n",
    "\n",
    "**Macro F1-Score Importance:**\n",
    "Essential for imbalanced datasets‚Äîit ensures the model performs well across ALL breeds regardless of sample size per class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49d5ac",
   "metadata": {},
   "source": [
    "## Performance Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training history\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plot training and validation accuracy and loss\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    epochs_range = range(1, len(history['train_acc']) + 1)\n",
    "\n",
    "    # Accuracy plot\n",
    "    axes[0].plot(epochs_range, history['train_acc'], label='Training Accuracy', marker='o')\n",
    "    axes[0].plot(epochs_range, history['val_acc'], label='Validation Accuracy', marker='s')\n",
    "    axes[0].set_title(f'{model_name} - Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Loss plot\n",
    "    axes[1].plot(epochs_range, history['train_loss'], label='Training Loss', marker='o')\n",
    "    axes[1].plot(epochs_range, history['val_loss'], label='Validation Loss', marker='s')\n",
    "    axes[1].set_title(f'{model_name} - Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print final metrics\n",
    "    final_train_acc = history['train_acc'][-1]\n",
    "    final_val_acc = history['val_acc'][-1]\n",
    "    final_train_loss = history['train_loss'][-1]\n",
    "    final_val_loss = history['val_loss'][-1]\n",
    "    best_val_acc = max(history['val_acc'])\n",
    "\n",
    "    print(f\"\\n{model_name} - Final Metrics:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
    "    print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "    print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "    print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30c53c",
   "metadata": {},
   "source": [
    "### ResNet18 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_resnet18, \"ResNet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652b5da",
   "metadata": {},
   "source": [
    "### ResNet50 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58176aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_resnet50, \"ResNet50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7dea4",
   "metadata": {},
   "source": [
    "### EfficientNetB1 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf41fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_efficientnet, \"EfficientNetB1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8773bd",
   "metadata": {},
   "source": [
    "### Comparative Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61318e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models - Training and Validation Accuracy\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "epochs_range_res18 = range(1, len(history_resnet18['train_acc']) + 1)\n",
    "epochs_range_res50 = range(1, len(history_resnet50['train_acc']) + 1)\n",
    "epochs_range_eff = range(1, len(history_efficientnet['train_acc']) + 1)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range_res18, history_resnet18['train_acc'], label='ResNet18', marker='o', linewidth=2)\n",
    "plt.plot(epochs_range_res50, history_resnet50['train_acc'], label='ResNet50', marker='s', linewidth=2)\n",
    "plt.plot(epochs_range_eff, history_efficientnet['train_acc'], label='EfficientNetB1', marker='^', linewidth=2)\n",
    "plt.title('Training Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range_res18, history_resnet18['val_acc'], label='ResNet18', marker='o', linewidth=2)\n",
    "plt.plot(epochs_range_res50, history_resnet50['val_acc'], label='ResNet50', marker='s', linewidth=2)\n",
    "plt.plot(epochs_range_eff, history_efficientnet['val_acc'], label='EfficientNetB1', marker='^', linewidth=2)\n",
    "plt.title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare all models - Training and Validation Loss\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range_res18, history_resnet18['train_loss'], label='ResNet18', marker='o', linewidth=2)\n",
    "plt.plot(epochs_range_res50, history_resnet50['train_loss'], label='ResNet50', marker='s', linewidth=2)\n",
    "plt.plot(epochs_range_eff, history_efficientnet['train_loss'], label='EfficientNetB1', marker='^', linewidth=2)\n",
    "plt.title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range_res18, history_resnet18['val_loss'], label='ResNet18', marker='o', linewidth=2)\n",
    "plt.plot(epochs_range_res50, history_resnet50['val_loss'], label='ResNet50', marker='s', linewidth=2)\n",
    "plt.plot(epochs_range_eff, history_efficientnet['val_loss'], label='EfficientNetB1', marker='^', linewidth=2)\n",
    "plt.title('Validation Loss Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3cb8e",
   "metadata": {},
   "source": [
    "## Evaluation: Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb481559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model and generate metrics\n",
    "def evaluate_model(model, model_name, data_loader):\n",
    "    \"\"\"Evaluate model and compute precision, recall, F1-score\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_preds)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = np.mean(y_pred == y_true)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"\\nOverall Metrics:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'{model_name} - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "# Evaluate models\n",
    "metrics_resnet18 = evaluate_model(resnet18_model, \"ResNet18\", val_loader)\n",
    "metrics_resnet50 = evaluate_model(resnet50_model, \"ResNet50\", val_loader)\n",
    "metrics_efficientnet = evaluate_model(efficientnet_model, \"EfficientNetB1\", val_loader)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['ResNet18', 'ResNet50', 'EfficientNetB1'],\n",
    "    'Accuracy': [metrics_resnet18['accuracy'], metrics_resnet50['accuracy'], metrics_efficientnet['accuracy']],\n",
    "    'Precision': [metrics_resnet18['precision'], metrics_resnet50['precision'], metrics_efficientnet['precision']],\n",
    "    'Recall': [metrics_resnet18['recall'], metrics_resnet50['recall'], metrics_efficientnet['recall']],\n",
    "    'F1-Score': [metrics_resnet18['f1_score'], metrics_resnet50['f1_score'], metrics_efficientnet['f1_score']],\n",
    "    'Best Val Accuracy': [max(history_resnet18['val_acc']), max(history_resnet50['val_acc']), max(history_efficientnet['val_acc'])],\n",
    "    'Final Val Loss': [history_resnet18['val_loss'][-1], history_resnet50['val_loss'][-1], history_efficientnet['val_loss'][-1]]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Highlight best model\n",
    "best_model_idx = comparison_df['Accuracy'].idxmax()\n",
    "best_model = comparison_df.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nüèÜ Best Performing Model: {best_model}\")\n",
    "print(f\"   Accuracy: {comparison_df.loc[best_model_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"   F1-Score: {comparison_df.loc[best_model_idx, 'F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b0447",
   "metadata": {},
   "source": [
    "## Next Steps / Usage\n",
    "- Run cells top-to-bottom to download data, prepare loaders, and train all three models.\n",
    "- If GPU memory is limited, reduce `BATCH_SIZE` or unfreeze only part of the backbones.\n",
    "- You can skip training some models by commenting their training calls.\n",
    "- Adjust `EPOCHS`, `LEARNING_RATE`, or augmentation if over/underfitting is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f52177",
   "metadata": {},
   "source": [
    "### EfficientNetB1 Performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
