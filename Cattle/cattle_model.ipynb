{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe81b78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[0;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzaidworks0508/cow-breed-classification-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"zaidworks0508/cow-breed-classification-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb10eb",
   "metadata": {},
   "source": [
    "# Cattle Breed Classification - Comparative Study\n",
    "\n",
    "This notebook compares three CNN architectures for cattle breed classification:\n",
    "1. ResNet18\n",
    "2. ResNet50\n",
    "3. EfficientNetB1\n",
    "\n",
    "Using the zaidworks0508/cow-breed-classification-dataset with transfer learning approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5712a6",
   "metadata": {},
   "source": [
    "## Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the downloaded dataset structure\n",
    "print(f\"Base path: {path}\")\n",
    "print(\"\\nExploring directory structure...\")\n",
    "\n",
    "def explore_directory(dir_path, max_depth=3, current_depth=0, prefix=\"\"):\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    try:\n",
    "        items = os.listdir(dir_path)\n",
    "        for item in items[:10]:  # Limit to first 10 items per directory\n",
    "            item_path = os.path.join(dir_path, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                print(f\"{prefix}üìÅ {item}/\")\n",
    "                explore_directory(item_path, max_depth, current_depth + 1, prefix + \"  \")\n",
    "            else:\n",
    "                print(f\"{prefix}üìÑ {item}\")\n",
    "    except PermissionError:\n",
    "        print(f\"{prefix}‚ùå Permission denied\")\n",
    "    except Exception as e:\n",
    "        print(f\"{prefix}‚ùå Error: {e}\")\n",
    "\n",
    "explore_directory(path, max_depth=4)\n",
    "\n",
    "# Find the dataset path\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Searching for cattle breed images...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataset_path = None\n",
    "for root, dirs, files in os.walk(path):\n",
    "    if any(item.endswith(('.jpg', '.jpeg', '.png')) for item in files):\n",
    "        dataset_path = root\n",
    "        print(f\"‚úÖ Found images at: {dataset_path}\")\n",
    "        break\n",
    "\n",
    "if dataset_path is None:\n",
    "    dataset_path = path\n",
    "    print(f\"Using base path as dataset path: {dataset_path}\")\n",
    "\n",
    "# List classes and count images\n",
    "classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "print(f\"\\nüìä Cattle breeds found: {sorted(classes)}\")\n",
    "\n",
    "print(\"\\nüìà Image counts per breed:\")\n",
    "total_images = 0\n",
    "for cls in sorted(classes):\n",
    "    cls_path = os.path.join(dataset_path, cls)\n",
    "    try:\n",
    "        num_images = len([f for f in os.listdir(cls_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        print(f\"  {cls}: {num_images:,} images\")\n",
    "        total_images += num_images\n",
    "    except Exception as e:\n",
    "        print(f\"  {cls}: Error - {e}\")\n",
    "\n",
    "print(f\"\\n  Total images: {total_images:,}\")\n",
    "print(f\"  Total breeds: {len(classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = 224  # Using 224x224 for pre-trained models\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Custom Dataset class\n",
    "class CattleDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        # Get class directories\n",
    "        classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_names = classes\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "        # Load all image paths and labels\n",
    "        for cls in classes:\n",
    "            cls_path = os.path.join(root_dir, cls)\n",
    "            cls_idx = self.class_to_idx[cls]\n",
    "            for img_name in os.listdir(cls_path):\n",
    "                if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    self.images.append(os.path.join(cls_path, img_name))\n",
    "                    self.labels.append(cls_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Data augmentation and preprocessing for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Only normalization for validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = CattleDataset(dataset_path, transform=None)\n",
    "class_names = full_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Total images: {len(full_dataset)}\")\n",
    "\n",
    "# Split dataset into train and validation\n",
    "from torch.utils.data import random_split\n",
    "train_size = int((1 - VALIDATION_SPLIT) * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_indices, val_indices = torch.utils.data.random_split(\n",
    "    range(len(full_dataset)),\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Create separate datasets with different transforms\n",
    "class SubsetDataset(Dataset):\n",
    "    def __init__(self, dataset, indices, transform):\n",
    "        self.dataset = dataset\n",
    "        self.indices = list(indices)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = self.indices[idx]\n",
    "        img_path = self.dataset.images[original_idx]\n",
    "        label = self.dataset.labels[original_idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "train_dataset = SubsetDataset(full_dataset, train_indices, train_transform)\n",
    "val_dataset = SubsetDataset(full_dataset, val_indices, val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Batches per epoch (train): {len(train_loader)}\")\n",
    "print(f\"Batches per epoch (val): {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc5927",
   "metadata": {},
   "source": [
    "## Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daafb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Denormalization for display\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "for i in range(min(9, len(images))):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "\n",
    "    # Convert tensor to image\n",
    "    img = images[i]\n",
    "    img = inv_normalize(img)\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[labels[i].item()])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e93fa3",
   "metadata": {},
   "source": [
    "## Training Infrastructure: Early Stopping & Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping implementation\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, model_name):\n",
    "    \"\"\"Train a PyTorch model with early stopping and learning rate scheduling\"\"\"\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    # History tracking\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            train_pbar.set_postfix({\n",
    "                'loss': f'{train_loss/len(train_loader):.4f}',\n",
    "                'acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]  ')\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                val_pbar.set_postfix({\n",
    "                    'loss': f'{val_loss/len(val_loader):.4f}',\n",
    "                    'acc': f'{100.*val_correct/val_total:.2f}%'\n",
    "                })\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_accuracy)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_accuracy)\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "        print(f'  Learning Rate: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(avg_val_loss)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if old_lr != new_lr:\n",
    "            print(f'  Learning rate reduced: {old_lr:.2e} -> {new_lr:.2e}')\n",
    "\n",
    "        # Early stopping check\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\nEarly stopping triggered!\")\n",
    "            model.load_state_dict(early_stopping.best_model)\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    if early_stopping.best_model is not None:\n",
    "        model.load_state_dict(early_stopping.best_model)\n",
    "        print(\"\\nRestored best model weights\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f908eb",
   "metadata": {},
   "source": [
    "## Model 1: ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet18 model\n",
    "def build_resnet18_model(num_classes=3):\n",
    "    \"\"\"Build ResNet18 model with frozen base and custom classifier\"\"\"\n",
    "\n",
    "    # Load pre-trained ResNet18\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace final fully connected layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "resnet18_model = build_resnet18_model(num_classes=num_classes)\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"ResNet18 Model Architecture:\")\n",
    "print(\"=\"*70)\n",
    "print(resnet18_model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in resnet18_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in resnet18_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c27d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet18\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_resnet18 = optim.Adam(resnet18_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "history_resnet18 = train_model(\n",
    "    resnet18_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_resnet18,\n",
    "    EPOCHS,\n",
    "    \"ResNet18\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e6287",
   "metadata": {},
   "source": [
    "## Model 2: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet50 model\n",
    "def build_resnet50_model(num_classes=3):\n",
    "    \"\"\"Build ResNet50 model with frozen base and custom classifier\"\"\"\n",
    "\n",
    "    # Load pre-trained ResNet50\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace final fully connected layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "resnet50_model = build_resnet50_model(num_classes=num_classes)\n",
    "resnet50_model = resnet50_model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"ResNet50 Model Architecture:\")\n",
    "print(\"=\"*70)\n",
    "print(resnet50_model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in resnet50_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in resnet50_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0811d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet50\n",
    "optimizer_resnet50 = optim.Adam(resnet50_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "history_resnet50 = train_model(\n",
    "    resnet50_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_resnet50,\n",
    "    EPOCHS,\n",
    "    \"ResNet50\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce220f",
   "metadata": {},
   "source": [
    "## Model 3: EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd74e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build EfficientNetB1 model\n",
    "def build_efficientnet_model(num_classes=3):\n",
    "    \"\"\"Build EfficientNet-B1 model with frozen base and custom classifier\"\"\"\n",
    "\n",
    "    # Load pre-trained EfficientNet-B1\n",
    "    model = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace classifier with custom layers\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "efficientnet_model = build_efficientnet_model(num_classes=num_classes)\n",
    "efficientnet_model = efficientnet_model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"EfficientNetB1 Model Architecture:\")\n",
    "print(\"=\"*70)\n",
    "print(efficientnet_model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in efficientnet_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in efficientnet_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EfficientNetB1\n",
    "optimizer_efficientnet = optim.Adam(efficientnet_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "history_efficientnet = train_model(\n",
    "    efficientnet_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_efficientnet,\n",
    "    EPOCHS,\n",
    "    \"EfficientNetB1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49d5ac",
   "metadata": {},
   "source": [
    "## Performance Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training history\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plot training and validation accuracy and loss\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    epochs_range = range(1, len(history['train_acc']) + 1)\n",
    "\n",
    "    # Accuracy plot\n",
    "    axes[0].plot(epochs_range, history['train_acc'], label='Training Accuracy', marker='o')\n",
    "    axes[0].plot(epochs_range, history['val_acc'], label='Validation Accuracy', marker='s')\n",
    "    axes[0].set_title(f'{model_name} - Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Loss plot\n",
    "    axes[1].plot(epochs_range, history['train_loss'], label='Training Loss', marker='o')\n",
    "    axes[1].plot(epochs_range, history['val_loss'], label='Validation Loss', marker='s')\n",
    "    axes[1].set_title(f'{model_name} - Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print final metrics\n",
    "    final_train_acc = history['train_acc'][-1]\n",
    "    final_val_acc = history['val_acc'][-1]\n",
    "    final_train_loss = history['train_loss'][-1]\n",
    "    final_val_loss = history['val_loss'][-1]\n",
    "    best_val_acc = max(history['val_acc'])\n",
    "\n",
    "    print(f\"\\n{model_name} - Final Metrics:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
    "    print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "    print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "    print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30c53c",
   "metadata": {},
   "source": [
    "### ResNet18 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_resnet18, \"ResNet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652b5da",
   "metadata": {},
   "source": [
    "### ResNet50 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58176aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_resnet50, \"ResNet50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7dea4",
   "metadata": {},
   "source": [
    "### EfficientNetB1 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf41fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_efficientnet, \"EfficientNetB1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8773bd",
   "metadata": {},
   "source": [
    "### Comparative Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61318e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models - Training and Validation Accuracy\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "epochs_range_res18 = range(1, len(history_resnet18['train_acc']) + 1)\n",
    "epochs_range_res50 = range(1, len(history_resnet50['train_acc']) + 1)\n",
    "epochs_range_eff = range(1, len(history_efficientnet['train_acc']) + 1)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range_res18, history_resnet18['train_acc'], label='ResNet18', marker='o', linewidth=2)\n",
    "plt.plot(epochs_range_res50, history_resnet50['train_acc'], label='ResNet50', marker='s', linewidth=2)\n",
    "plt.plot(epochs_range_eff, history_efficientnet['train_acc'], label='EfficientNetB1', marker='^', linewidth=2)\n",
    "plt.title('Training Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range_res18, history_resnet18['val_acc'], label='ResNet18', marker='o', linewidth=2)\n",
    "plt.plot(epochs_range_res50, history_resnet50['val_acc'], label='ResNet50', marker='s', linewidth=2)\n",
    "plt.plot(epochs_range_eff, history_efficientnet['val_acc'], label='EfficientNetB1', marker='^', linewidth=2)\n",
    "plt.title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare all models - Training and Validation Loss\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range_res18, history_resnet18['train_loss'], label='ResNet18', marker='o', linewidth=2)\n",
    "plt.plot(epochs_range_res50, history_resnet50['train_loss'], label='ResNet50', marker='s', linewidth=2)\n",
    "plt.plot(epochs_range_eff, history_efficientnet['train_loss'], label='EfficientNetB1', marker='^', linewidth=2)\n",
    "plt.title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range_res18, history_resnet18['val_loss'], label='ResNet18', marker='o', linewidth=2)\n",
    "plt.plot(epochs_range_res50, history_resnet50['val_loss'], label='ResNet50', marker='s', linewidth=2)\n",
    "plt.plot(epochs_range_eff, history_efficientnet['val_loss'], label='EfficientNetB1', marker='^', linewidth=2)\n",
    "plt.title('Validation Loss Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3cb8e",
   "metadata": {},
   "source": [
    "## Evaluation: Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb481559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model and generate metrics\n",
    "def evaluate_model(model, model_name, data_loader):\n",
    "    \"\"\"Evaluate model and compute precision, recall, F1-score\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_preds)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = np.mean(y_pred == y_true)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"\\nOverall Metrics:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'{model_name} - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "# Evaluate models\n",
    "metrics_resnet18 = evaluate_model(resnet18_model, \"ResNet18\", val_loader)\n",
    "metrics_resnet50 = evaluate_model(resnet50_model, \"ResNet50\", val_loader)\n",
    "metrics_efficientnet = evaluate_model(efficientnet_model, \"EfficientNetB1\", val_loader)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['ResNet18', 'ResNet50', 'EfficientNetB1'],\n",
    "    'Accuracy': [metrics_resnet18['accuracy'], metrics_resnet50['accuracy'], metrics_efficientnet['accuracy']],\n",
    "    'Precision': [metrics_resnet18['precision'], metrics_resnet50['precision'], metrics_efficientnet['precision']],\n",
    "    'Recall': [metrics_resnet18['recall'], metrics_resnet50['recall'], metrics_efficientnet['recall']],\n",
    "    'F1-Score': [metrics_resnet18['f1_score'], metrics_resnet50['f1_score'], metrics_efficientnet['f1_score']],\n",
    "    'Best Val Accuracy': [max(history_resnet18['val_acc']), max(history_resnet50['val_acc']), max(history_efficientnet['val_acc'])],\n",
    "    'Final Val Loss': [history_resnet18['val_loss'][-1], history_resnet50['val_loss'][-1], history_efficientnet['val_loss'][-1]]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Highlight best model\n",
    "best_model_idx = comparison_df['Accuracy'].idxmax()\n",
    "best_model = comparison_df.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nüèÜ Best Performing Model: {best_model}\")\n",
    "print(f\"   Accuracy: {comparison_df.loc[best_model_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"   F1-Score: {comparison_df.loc[best_model_idx, 'F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b0447",
   "metadata": {},
   "source": [
    "## Next Steps / Usage\n",
    "- Run cells top-to-bottom to download data, prepare loaders, and train all three models.\n",
    "- If GPU memory is limited, reduce `BATCH_SIZE` or unfreeze only part of the backbones.\n",
    "- You can skip training some models by commenting their training calls.\n",
    "- Adjust `EPOCHS`, `LEARNING_RATE`, or augmentation if over/underfitting is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f52177",
   "metadata": {},
   "source": [
    "### EfficientNetB1 Performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
